{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "CSCI-513 Project\\\n",
        "April 2025\\\n",
        "Lon Cherryhomes, Sr."
      ],
      "metadata": {
        "id": "Fp8AKfq2rEub"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fko1aGQ3buMA"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from pprint import pprint, pformat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4zsrnv7WtVqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c89e200-d6f4-45f3-c157-8a5a0b2ad83c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Cython in /usr/local/lib/python3.11/dist-packages (3.0.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install Cython\n",
        "%load_ext cython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uaCMt0K9p5BY"
      },
      "outputs": [],
      "source": [
        "%%cython\n",
        "\n",
        "cdef int pos\n",
        "cdef bytes subject\n",
        "\n",
        "cdef void factor():\n",
        "    global pos, subject\n",
        "    if   subject[pos] == ord('+'): pos += 1; factor()\n",
        "    elif subject[pos] == ord('-'): pos += 1; factor()\n",
        "    elif subject[pos] == ord('('):\n",
        "        pos += 1\n",
        "        expr()\n",
        "        if subject[pos] == ord(')'): pos += 1\n",
        "        else: raise Exception(pos)\n",
        "    elif subject[pos] == ord('x'): pos += 1\n",
        "    elif subject[pos] == ord('y'): pos += 1\n",
        "    elif subject[pos] == ord('0'): pos += 1\n",
        "    elif subject[pos] == ord('1'): pos += 1\n",
        "    else: raise Exception(pos)\n",
        "\n",
        "cdef void term():\n",
        "    global pos, subject\n",
        "    factor()\n",
        "    while (  subject[pos] == ord('*')\n",
        "          or subject[pos] == ord('/')\n",
        "          ):\n",
        "          pos += 1\n",
        "          term()\n",
        "\n",
        "cdef void expr():\n",
        "    global pos, subject\n",
        "    term()\n",
        "    while (  subject[pos] == ord('+')\n",
        "          or subject[pos] == ord('-')\n",
        "          ):\n",
        "          pos += 1\n",
        "          expr()\n",
        "\n",
        "cdef void stmt():\n",
        "    global pos, subject\n",
        "    expr()\n",
        "    if subject[pos] != ord('\\n'):\n",
        "        raise Exception(pos)\n",
        "\n",
        "def parse_expression(s):\n",
        "    global pos; pos = 0\n",
        "    global subject; subject = f\"{s}\\n\".encode('ascii')\n",
        "    try: stmt()\n",
        "    except Exception as e:\n",
        "        return e.args[0]+1\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dgUwnme7YjFe"
      },
      "outputs": [],
      "source": [
        "from itertools import product\n",
        "total = None\n",
        "tokens = \"(x*-1+0/y)\"\n",
        "def expressions(length):\n",
        "    global total; total = 1\n",
        "    for toks in product(tokens, repeat=length):\n",
        "        expression = \"\".join(toks)\n",
        "        yield (parse_expression(expression), expression)\n",
        "        total += 1\n",
        "    total -= 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9g2lu8aYNeIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0f5a112-af78-4008-f7b5-2623a0f606ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 10, 0.006108, [40.0, 30.0, 30.0]]\n",
            "[2, 100, 0.000289, [8.0, 30.0, 33.0, 29.0]]\n",
            "[3, 1000, 0.007784, [8.4, 30.0, 33.0, 14.3, 14.3]]\n",
            "[4, 10000, 0.096411, [3.04, 30.0, 33.0, 14.3, 9.73, 9.93]]\n",
            "[5, 100000, 0.484053, [2.1, 30.0, 33.0, 14.3, 9.73, 5.219, 5.651]]\n",
            "[6, 1000000, 4.564928, [0.9624, 30.0, 33.0, 14.3, 9.73, 5.219, 3.2049, 3.5837]]\n",
            "[7,\n",
            " 10000000,\n",
            " 27.392036,\n",
            " [0.57892, 30.0, 33.0, 14.3, 9.73, 5.219, 3.2049, 1.83727, 2.12991]]\n"
          ]
        }
      ],
      "source": [
        "for length in range(1, 8):\n",
        "    start = time.time_ns() // 1000\n",
        "    classes = [0] * (length+2)\n",
        "    for expr in expressions(length):\n",
        "        classes[expr[0]] += 1\n",
        "    finish = time.time_ns() // 1000\n",
        "    classes = [(c * 100.0 / total) for c in classes]\n",
        "    pprint([length, total, (finish - start) / 1000000.0, classes])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FRzNj9C4UBhu"
      },
      "outputs": [],
      "source": [
        "token_map = {'(': 1, 'x': 2, '0': 3, '+': 4, '*': 5, '/': 6, '-': 7, '1': 8, 'y': 9, ')': 10}\n",
        "def EXPRESSIONS(length):\n",
        "    XS = []\n",
        "    for expr in expressions(length):\n",
        "        XS.append([expr[0]] + [token_map[x] for x in expr[1]])\n",
        "    return XS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8X4k0PuhGqfC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d5794a7-a000-400a-875d-724f65b2834b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sklearn: 1. Logistic Regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       1.0\n",
            "           1       0.00      0.00      0.00       1.0\n",
            "           2       0.00      0.00      0.00       1.0\n",
            "\n",
            "    accuracy                           0.00       3.0\n",
            "   macro avg       0.00      0.00      0.00       3.0\n",
            "weighted avg       0.00      0.00      0.00       3.0\n",
            "\n",
            "sklearn: 1. MultinomialNB\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      1.00      0.50         1\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.33         3\n",
            "   macro avg       0.11      0.33      0.17         3\n",
            "weighted avg       0.11      0.33      0.17         3\n",
            "\n",
            "sklearn: 1. Support Vector Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      1.00      0.50         1\n",
            "           1       0.00      0.00      0.00         1\n",
            "           2       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.33         3\n",
            "   macro avg       0.11      0.33      0.17         3\n",
            "weighted avg       0.11      0.33      0.17         3\n",
            "\n",
            "sklearn: 1. Random Forest Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       0.50      1.00      0.67         1\n",
            "           2       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.67         3\n",
            "   macro avg       0.50      0.67      0.56         3\n",
            "weighted avg       0.50      0.67      0.56         3\n",
            "\n",
            "sklearn: 1. Decision Tree Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       0.50      1.00      0.67         1\n",
            "           2       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.67         3\n",
            "   macro avg       0.50      0.67      0.56         3\n",
            "weighted avg       0.50      0.67      0.56         3\n",
            "\n",
            "sklearn: 1. Comparison\n",
            "                           accuracy  precision    recall        F1\n",
            "Logistic Regression        0.000000   0.000000  0.000000  0.000000\n",
            "MultinomialNB              0.333333   0.111111  0.333333  0.166667\n",
            "Support Vector Classifier  0.333333   0.111111  0.333333  0.166667\n",
            "Random Forest Classifier   0.666667   0.500000  0.666667  0.555556\n",
            "Decision Tree Classifier   0.666667   0.500000  0.666667  0.555556\n",
            "\n",
            "sklearn: 2. Logistic Regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.46      0.67      0.55         9\n",
            "           2       0.38      0.30      0.33        10\n",
            "           3       0.56      0.56      0.56         9\n",
            "\n",
            "    accuracy                           0.47        30\n",
            "   macro avg       0.35      0.38      0.36        30\n",
            "weighted avg       0.43      0.47      0.44        30\n",
            "\n",
            "sklearn: 2. MultinomialNB\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.44      0.78      0.56         9\n",
            "           2       0.29      0.40      0.33        10\n",
            "           3       0.00      0.00      0.00         9\n",
            "\n",
            "    accuracy                           0.37        30\n",
            "   macro avg       0.18      0.29      0.22        30\n",
            "weighted avg       0.23      0.37      0.28        30\n",
            "\n",
            "sklearn: 2. Support Vector Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.44      0.78      0.56         9\n",
            "           2       0.40      0.20      0.27        10\n",
            "           3       0.56      0.56      0.56         9\n",
            "\n",
            "    accuracy                           0.47        30\n",
            "   macro avg       0.35      0.38      0.35        30\n",
            "weighted avg       0.43      0.47      0.42        30\n",
            "\n",
            "sklearn: 2. Random Forest Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       0.67      0.60      0.63        10\n",
            "           3       0.64      0.78      0.70         9\n",
            "\n",
            "    accuracy                           0.73        30\n",
            "   macro avg       0.58      0.59      0.58        30\n",
            "weighted avg       0.71      0.73      0.72        30\n",
            "\n",
            "sklearn: 2. Decision Tree Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.50      0.40         2\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       0.78      0.78      0.78         9\n",
            "\n",
            "    accuracy                           0.87        30\n",
            "   macro avg       0.78      0.79      0.78        30\n",
            "weighted avg       0.89      0.87      0.88        30\n",
            "\n",
            "sklearn: 2. Comparison\n",
            "                           accuracy  precision    recall        F1\n",
            "Logistic Regression        0.466667   0.430128  0.466667  0.441414\n",
            "MultinomialNB              0.366667   0.226488  0.366667  0.279111\n",
            "Support Vector Classifier  0.466667   0.431250  0.466667  0.423556\n",
            "Random Forest Classifier   0.733333   0.713131  0.733333  0.720526\n",
            "Decision Tree Classifier   0.866667   0.888889  0.866667  0.875789\n",
            "\n",
            "sklearn: 3. Logistic Regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        25\n",
            "           1       0.30      0.39      0.34        90\n",
            "           2       0.30      0.49      0.37        99\n",
            "           3       0.33      0.02      0.04        43\n",
            "           4       0.24      0.09      0.13        43\n",
            "\n",
            "    accuracy                           0.30       300\n",
            "   macro avg       0.23      0.20      0.18       300\n",
            "weighted avg       0.27      0.30      0.25       300\n",
            "\n",
            "sklearn: 3. MultinomialNB\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        25\n",
            "           1       0.38      0.48      0.42        90\n",
            "           2       0.37      0.64      0.46        99\n",
            "           3       0.43      0.14      0.21        43\n",
            "           4       0.00      0.00      0.00        43\n",
            "\n",
            "    accuracy                           0.37       300\n",
            "   macro avg       0.23      0.25      0.22       300\n",
            "weighted avg       0.30      0.37      0.31       300\n",
            "\n",
            "sklearn: 3. Support Vector Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        25\n",
            "           1       0.47      0.84      0.60        90\n",
            "           2       0.54      0.69      0.60        99\n",
            "           3       0.50      0.02      0.04        43\n",
            "           4       0.12      0.02      0.04        43\n",
            "\n",
            "    accuracy                           0.49       300\n",
            "   macro avg       0.33      0.32      0.26       300\n",
            "weighted avg       0.41      0.49      0.39       300\n",
            "\n",
            "sklearn: 3. Random Forest Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.88      0.85        25\n",
            "           1       0.98      1.00      0.99        90\n",
            "           2       0.91      0.90      0.90        99\n",
            "           3       0.87      0.63      0.73        43\n",
            "           4       0.73      0.88      0.80        43\n",
            "\n",
            "    accuracy                           0.89       300\n",
            "   macro avg       0.86      0.86      0.85       300\n",
            "weighted avg       0.89      0.89      0.88       300\n",
            "\n",
            "sklearn: 3. Decision Tree Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92        25\n",
            "           1       1.00      1.00      1.00        90\n",
            "           2       1.00      0.99      0.99        99\n",
            "           3       0.74      0.72      0.73        43\n",
            "           4       0.78      0.81      0.80        43\n",
            "\n",
            "    accuracy                           0.92       300\n",
            "   macro avg       0.89      0.89      0.89       300\n",
            "weighted avg       0.92      0.92      0.92       300\n",
            "\n",
            "sklearn: 3. Comparison\n",
            "                           accuracy  precision    recall        F1\n",
            "Logistic Regression        0.296667   0.270808  0.296667  0.250282\n",
            "MultinomialNB              0.373333   0.295459  0.373333  0.310078\n",
            "Support Vector Classifier  0.486667   0.406154  0.486667  0.390813\n",
            "Random Forest Classifier   0.886667   0.890656  0.886667  0.884650\n",
            "Decision Tree Classifier   0.923333   0.923942  0.923333  0.923556\n",
            "\n",
            "sklearn: 4. Logistic Regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        91\n",
            "           1       0.29      0.39      0.34       900\n",
            "           2       0.31      0.56      0.40       990\n",
            "           3       0.00      0.00      0.00       429\n",
            "           4       0.00      0.00      0.00       292\n",
            "           5       0.14      0.00      0.01       298\n",
            "\n",
            "    accuracy                           0.30      3000\n",
            "   macro avg       0.12      0.16      0.12      3000\n",
            "weighted avg       0.20      0.30      0.23      3000\n",
            "\n",
            "sklearn: 4. MultinomialNB\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        91\n",
            "           1       0.41      0.58      0.48       900\n",
            "           2       0.37      0.63      0.47       990\n",
            "           3       0.43      0.04      0.08       429\n",
            "           4       0.00      0.00      0.00       292\n",
            "           5       0.00      0.00      0.00       298\n",
            "\n",
            "    accuracy                           0.39      3000\n",
            "   macro avg       0.20      0.21      0.17      3000\n",
            "weighted avg       0.31      0.39      0.31      3000\n",
            "\n",
            "sklearn: 4. Support Vector Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        91\n",
            "           1       0.67      1.00      0.80       900\n",
            "           2       0.56      0.90      0.69       990\n",
            "           3       0.35      0.04      0.07       429\n",
            "           4       0.00      0.00      0.00       292\n",
            "           5       1.00      0.01      0.02       298\n",
            "\n",
            "    accuracy                           0.60      3000\n",
            "   macro avg       0.43      0.32      0.26      3000\n",
            "weighted avg       0.53      0.60      0.48      3000\n",
            "\n",
            "sklearn: 4. Random Forest Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94        91\n",
            "           1       1.00      1.00      1.00       900\n",
            "           2       1.00      1.00      1.00       990\n",
            "           3       0.99      1.00      0.99       429\n",
            "           4       0.96      0.90      0.93       292\n",
            "           5       0.93      0.96      0.94       298\n",
            "\n",
            "    accuracy                           0.98      3000\n",
            "   macro avg       0.97      0.97      0.97      3000\n",
            "weighted avg       0.98      0.98      0.98      3000\n",
            "\n",
            "sklearn: 4. Decision Tree Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.99      0.92        91\n",
            "           1       1.00      1.00      1.00       900\n",
            "           2       1.00      1.00      1.00       990\n",
            "           3       0.96      0.97      0.97       429\n",
            "           4       0.91      0.91      0.91       292\n",
            "           5       0.95      0.91      0.93       298\n",
            "\n",
            "    accuracy                           0.98      3000\n",
            "   macro avg       0.95      0.96      0.95      3000\n",
            "weighted avg       0.98      0.98      0.98      3000\n",
            "\n",
            "sklearn: 4. Comparison\n",
            "                           accuracy  precision    recall        F1\n",
            "Logistic Regression        0.304000   0.204984  0.304000  0.233935\n",
            "MultinomialNB              0.387000   0.306045  0.387000  0.308587\n",
            "Support Vector Classifier  0.603000   0.533570  0.603000  0.478860\n",
            "Random Forest Classifier   0.984667   0.984810  0.984667  0.984617\n",
            "Decision Tree Classifier   0.977000   0.977333  0.977000  0.976985\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "#-------------------------------------------------------------------------------\n",
        "results = {}\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "for length in range(1, 5):\n",
        "    columns = ['target'] + [f\"x{i}\" for i in range(1, length+1)]\n",
        "    data = pd.DataFrame(EXPRESSIONS(length), columns=columns)\n",
        "    X = data.iloc[:, 1:length+1]\n",
        "    y = data.iloc[:, 0]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=53, stratify=y\n",
        "    )\n",
        "    models = {\n",
        "        \"Logistic Regression\": LogisticRegression(max_iter=200),\n",
        "        \"MultinomialNB\": MultinomialNB(),\n",
        "        \"Support Vector Classifier\": SVC(),\n",
        "        \"Random Forest Classifier\": RandomForestClassifier(n_estimators=100),\n",
        "        \"Decision Tree Classifier\": DecisionTreeClassifier()\n",
        "    }\n",
        "#   ----------------------------------------------------------------------------\n",
        "    results[length] = {}\n",
        "    for model_name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        results[length][model_name] = {\n",
        "            \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "            \"precision\": precision_score(y_test, y_pred, average='weighted'),\n",
        "            \"recall\": recall_score(y_test, y_pred, average='weighted'),\n",
        "            \"F1\": f1_score(y_test, y_pred, average='weighted')\n",
        "        }\n",
        "        print(f\"sklearn: {length}. {model_name}\")\n",
        "        print(classification_report(y_test, y_pred))\n",
        "#   ----------------------------------------------------------------------------\n",
        "    comparison = pd.DataFrame(\n",
        "    { model_name: {\n",
        "          \"accuracy\": metrics[\"accuracy\"],\n",
        "          \"precision\": metrics[\"precision\"],\n",
        "          \"recall\": metrics[\"recall\"],\n",
        "          \"F1\": metrics[\"F1\"]\n",
        "      } for model_name, metrics in results[length].items()\n",
        "    }).T\n",
        "    print(f\"sklearn: {length}. Comparison\")\n",
        "    print(comparison)\n",
        "    print()\n",
        "#-------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio"
      ],
      "metadata": {
        "id": "hOzjReG-NKgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7439850-77a0-4746-8743-c05051117c07"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "#-------------------------------------------------------------------------------\n",
        "vocab_size = 11\n",
        "embedding_dim = 8\n",
        "hidden_dim = 32\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 20\n",
        "#-------------------------------------------------------------------------------\n",
        "# Model 1: Logistic Regression (a single linear layer after embedding+flattening)\n",
        "class LogisticRegressionModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, num_classes, seq_length):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.fc = nn.Linear(seq_length * embedding_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, seq_length]\n",
        "        x = self.embedding(x) # shape: [batch_size, seq_length, embedding_dim]\n",
        "        x = x.view(x.size(0), -1) # flatten to [batch_size, seq_length*embedding_dim]\n",
        "        out = self.fc(x)\n",
        "        return out\n",
        "#-------------------------------------------------------------------------------\n",
        "# Model 2: Feedforward network with one hidden layer\n",
        "class FeedforwardNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, num_classes, seq_length, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.fc1 = nn.Linear(seq_length * embedding_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        out = self.fc2(x)\n",
        "        return out\n",
        "#-------------------------------------------------------------------------------\n",
        "# Model 3: Deeper network with two hidden layers\n",
        "class DeeperNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, num_classes, seq_length, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.fc1 = nn.Linear(seq_length * embedding_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        out = self.fc3(x)\n",
        "        return out\n",
        "#-------------------------------------------------------------------------------\n",
        "# Model 4: RNN using an LSTM (the hidden state of the last time step is used for classification)\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, num_classes, hidden_dim, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x) # [batch, seq_length, embedding_dim]\n",
        "        out, (hn, cn) = self.lstm(x) # hn: [num_layers, batch, hidden_dim]\n",
        "        out = self.fc(hn[-1]) # use last layer’s hidden state for classification\n",
        "        return out\n",
        "#-------------------------------------------------------------------------------\n",
        "# Model 5: Transformer-based Model (using a single encoder layer)\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, num_classes, seq_length, nhead=2, num_encoder_layers=1, dim_feedforward=64):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # Learnable positional encoding (for simplicity)\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, seq_length, embedding_dim))\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=nhead, dim_feedforward=dim_feedforward)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
        "        self.fc = nn.Linear(seq_length * embedding_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x) + self.pos_embedding # [batch, seq_length, embedding_dim]\n",
        "        x = x.transpose(0, 1) # Transformer expects: [seq_length, batch, embedding_dim]\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = x.transpose(0, 1) # back to [batch, seq_length, embedding_dim]\n",
        "        x = x.reshape(x.size(0), -1) # flatten\n",
        "        out = self.fc(x)\n",
        "        return out\n",
        "#-------------------------------------------------------------------------------\n",
        "# Model 6: Convolutional Neural Network (CNN) with 1D Convolutions\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, num_classes, seq_length, num_filters=16, kernel_size=2):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # For conv1d, we expect input of shape (batch, channels, seq_length)\n",
        "        self.conv1 = nn.Conv1d(in_channels=embedding_dim, out_channels=num_filters, kernel_size=kernel_size)\n",
        "        conv_output_size = seq_length - kernel_size + 1\n",
        "        self.fc = nn.Linear(num_filters * conv_output_size, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x) # [batch, seq_length, embedding_dim]\n",
        "        x = x.transpose(1, 2) # [batch, embedding_dim, seq_length]\n",
        "        x = self.conv1(x) # [batch, num_filters, new_seq_length]\n",
        "        x = self.relu(x)\n",
        "        x = x.view(x.size(0), -1) # flatten\n",
        "        out = self.fc(x)\n",
        "        return out\n",
        "#-------------------------------------------------------------------------------\n",
        "def train_model(model, train_loader, criterion, optimizer, device, epochs=20):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "        for batch_x, batch_y in train_loader:\n",
        "            batch_x = batch_x.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_x)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")\n",
        "#-------------------------------------------------------------------------------\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in test_loader:\n",
        "            batch_x = batch_x.to(device)\n",
        "            outputs = model(batch_x)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_labels.append(batch_y)\n",
        "    all_preds = torch.cat(all_preds).numpy()\n",
        "    all_labels = torch.cat(all_labels).numpy()\n",
        "    return all_preds, all_labels\n",
        "#-------------------------------------------------------------------------------\n",
        "results = {}\n",
        "for length in range(2, 5):\n",
        "    data = np.array(EXPRESSIONS(length))\n",
        "    X = data[:, 1:].astype(np.int64) # tokens (shape: [n_samples, n_columns])\n",
        "    y = data[:, 0].astype(np.int64)\n",
        "    num_classes = int(y.max()) + 1\n",
        "    seq_length = X.shape[1]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=53)\n",
        "    batch_size = 32\n",
        "    train_dataset = TensorDataset(\n",
        "        torch.tensor(X_train, dtype=torch.long),\n",
        "        torch.tensor(y_train, dtype=torch.long))\n",
        "    test_dataset = TensorDataset(\n",
        "        torch.tensor(X_test, dtype=torch.long),\n",
        "        torch.tensor(y_test, dtype=torch.long))\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "#   ----------------------------------------------------------------------------\n",
        "    models = {\n",
        "        \"Logistic Regression\": LogisticRegressionModel(vocab_size, embedding_dim, num_classes, seq_length),\n",
        "        \"Feedforward NN\": FeedforwardNN(vocab_size, embedding_dim, num_classes, seq_length, hidden_dim),\n",
        "        \"Deeper NN\": DeeperNN(vocab_size, embedding_dim, num_classes, seq_length, hidden_dim),\n",
        "        \"RNN (LSTM)\": RNNModel(vocab_size, embedding_dim, num_classes, hidden_dim),\n",
        "        \"Transformer\": TransformerModel(vocab_size, embedding_dim, num_classes, seq_length),\n",
        "        \"CNN\": CNNModel(vocab_size, embedding_dim, num_classes, seq_length)\n",
        "    }\n",
        "#   ----------------------------------------------------------------------------\n",
        "    results[length] = {}\n",
        "    for model_name, model in models.items():\n",
        "        print(f\"Training model: {model_name}\")\n",
        "        model.to(device)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "        train_model(model, train_loader, criterion, optimizer, device, epochs=EPOCHS)\n",
        "        preds, labels = evaluate_model(model, test_loader, device)\n",
        "        results[length][model_name] = {\n",
        "            \"accuracy\": accuracy_score(labels, preds),\n",
        "            \"precision\": precision_score(labels, preds, average='weighted', zero_division=0),\n",
        "            \"recall\": recall_score(labels, preds, average='weighted', zero_division=0),\n",
        "            \"F1\": f1_score(labels, preds, average='weighted', zero_division=0),\n",
        "        }\n",
        "        print(f\"PyTorch: {length}. {model_name}:\")\n",
        "        print(classification_report(labels, preds, zero_division=0))\n",
        "#   ----------------------------------------------------------------------------\n",
        "    comparison = pd.DataFrame(\n",
        "    { model_name: {\n",
        "          \"accuracy\": metrics[\"accuracy\"],\n",
        "          \"precision\": metrics[\"precision\"],\n",
        "          \"recall\": metrics[\"recall\"],\n",
        "          \"F1\": metrics[\"F1\"]\n",
        "      } for model_name, metrics in results[length].items()\n",
        "    }).T\n",
        "    print(f\"PyTorch: {length}. Comparison\")\n",
        "    print(comparison)\n",
        "    print()\n",
        "#-------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "h7PbdwwzZQSW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd166f95-58e5-463a-d77b-e709bf337b0a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Training model: Logistic Regression\n",
            "Epoch [1/20], Loss: 1.7325\n",
            "Epoch [2/20], Loss: 1.7108\n",
            "Epoch [3/20], Loss: 1.6381\n",
            "Epoch [4/20], Loss: 1.6382\n",
            "Epoch [5/20], Loss: 1.6184\n",
            "Epoch [6/20], Loss: 1.6016\n",
            "Epoch [7/20], Loss: 1.5869\n",
            "Epoch [8/20], Loss: 1.6098\n",
            "Epoch [9/20], Loss: 1.5680\n",
            "Epoch [10/20], Loss: 1.5762\n",
            "Epoch [11/20], Loss: 1.5250\n",
            "Epoch [12/20], Loss: 1.5267\n",
            "Epoch [13/20], Loss: 1.5270\n",
            "Epoch [14/20], Loss: 1.4872\n",
            "Epoch [15/20], Loss: 1.5160\n",
            "Epoch [16/20], Loss: 1.4903\n",
            "Epoch [17/20], Loss: 1.4695\n",
            "Epoch [18/20], Loss: 1.4696\n",
            "Epoch [19/20], Loss: 1.4472\n",
            "Epoch [20/20], Loss: 1.4420\n",
            "PyTorch: 2. Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.50      0.40         2\n",
            "           1       0.00      0.00      0.00         6\n",
            "           2       0.00      0.00      0.00         8\n",
            "           3       0.17      0.50      0.25         4\n",
            "\n",
            "    accuracy                           0.15        20\n",
            "   macro avg       0.12      0.25      0.16        20\n",
            "weighted avg       0.07      0.15      0.09        20\n",
            "\n",
            "Training model: Feedforward NN\n",
            "Epoch [1/20], Loss: 1.3927\n",
            "Epoch [2/20], Loss: 1.3716\n",
            "Epoch [3/20], Loss: 1.3541\n",
            "Epoch [4/20], Loss: 1.3533\n",
            "Epoch [5/20], Loss: 1.3342\n",
            "Epoch [6/20], Loss: 1.3174\n",
            "Epoch [7/20], Loss: 1.3057\n",
            "Epoch [8/20], Loss: 1.2896\n",
            "Epoch [9/20], Loss: 1.2829\n",
            "Epoch [10/20], Loss: 1.2598\n",
            "Epoch [11/20], Loss: 1.2692\n",
            "Epoch [12/20], Loss: 1.2463\n",
            "Epoch [13/20], Loss: 1.2510\n",
            "Epoch [14/20], Loss: 1.2232\n",
            "Epoch [15/20], Loss: 1.2234\n",
            "Epoch [16/20], Loss: 1.1853\n",
            "Epoch [17/20], Loss: 1.1949\n",
            "Epoch [18/20], Loss: 1.1585\n",
            "Epoch [19/20], Loss: 1.1625\n",
            "Epoch [20/20], Loss: 1.1448\n",
            "PyTorch: 2. Feedforward NN:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.00      0.00      0.00         6\n",
            "           2       0.46      0.75      0.57         8\n",
            "           3       0.25      0.25      0.25         4\n",
            "\n",
            "    accuracy                           0.35        20\n",
            "   macro avg       0.18      0.25      0.21        20\n",
            "weighted avg       0.23      0.35      0.28        20\n",
            "\n",
            "Training model: Deeper NN\n",
            "Epoch [1/20], Loss: 1.3886\n",
            "Epoch [2/20], Loss: 1.3738\n",
            "Epoch [3/20], Loss: 1.3634\n",
            "Epoch [4/20], Loss: 1.3521\n",
            "Epoch [5/20], Loss: 1.3428\n",
            "Epoch [6/20], Loss: 1.3385\n",
            "Epoch [7/20], Loss: 1.3354\n",
            "Epoch [8/20], Loss: 1.3264\n",
            "Epoch [9/20], Loss: 1.3195\n",
            "Epoch [10/20], Loss: 1.3001\n",
            "Epoch [11/20], Loss: 1.2879\n",
            "Epoch [12/20], Loss: 1.2881\n",
            "Epoch [13/20], Loss: 1.2708\n",
            "Epoch [14/20], Loss: 1.2568\n",
            "Epoch [15/20], Loss: 1.2607\n",
            "Epoch [16/20], Loss: 1.2270\n",
            "Epoch [17/20], Loss: 1.2219\n",
            "Epoch [18/20], Loss: 1.2123\n",
            "Epoch [19/20], Loss: 1.2166\n",
            "Epoch [20/20], Loss: 1.1821\n",
            "PyTorch: 2. Deeper NN:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       1.00      0.17      0.29         6\n",
            "           2       0.42      0.62      0.50         8\n",
            "           3       0.29      0.50      0.36         4\n",
            "\n",
            "    accuracy                           0.40        20\n",
            "   macro avg       0.43      0.32      0.29        20\n",
            "weighted avg       0.52      0.40      0.36        20\n",
            "\n",
            "Training model: RNN (LSTM)\n",
            "Epoch [1/20], Loss: 1.3995\n",
            "Epoch [2/20], Loss: 1.3983\n",
            "Epoch [3/20], Loss: 1.3955\n",
            "Epoch [4/20], Loss: 1.3735\n",
            "Epoch [5/20], Loss: 1.3757\n",
            "Epoch [6/20], Loss: 1.3770\n",
            "Epoch [7/20], Loss: 1.3664\n",
            "Epoch [8/20], Loss: 1.3625\n",
            "Epoch [9/20], Loss: 1.3603\n",
            "Epoch [10/20], Loss: 1.3381\n",
            "Epoch [11/20], Loss: 1.3346\n",
            "Epoch [12/20], Loss: 1.3348\n",
            "Epoch [13/20], Loss: 1.3336\n",
            "Epoch [14/20], Loss: 1.3252\n",
            "Epoch [15/20], Loss: 1.3123\n",
            "Epoch [16/20], Loss: 1.3047\n",
            "Epoch [17/20], Loss: 1.2886\n",
            "Epoch [18/20], Loss: 1.2772\n",
            "Epoch [19/20], Loss: 1.2719\n",
            "Epoch [20/20], Loss: 1.2628\n",
            "PyTorch: 2. RNN (LSTM):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.56      0.83      0.67         6\n",
            "           2       0.45      0.62      0.53         8\n",
            "           3       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.50        20\n",
            "   macro avg       0.25      0.36      0.30        20\n",
            "weighted avg       0.35      0.50      0.41        20\n",
            "\n",
            "Training model: Transformer\n",
            "Epoch [1/20], Loss: 1.4076\n",
            "Epoch [2/20], Loss: 1.3564\n",
            "Epoch [3/20], Loss: 1.3409\n",
            "Epoch [4/20], Loss: 1.3121\n",
            "Epoch [5/20], Loss: 1.2687\n",
            "Epoch [6/20], Loss: 1.2413\n",
            "Epoch [7/20], Loss: 1.2212\n",
            "Epoch [8/20], Loss: 1.2215\n",
            "Epoch [9/20], Loss: 1.1627\n",
            "Epoch [10/20], Loss: 1.2114\n",
            "Epoch [11/20], Loss: 1.1856\n",
            "Epoch [12/20], Loss: 1.1655\n",
            "Epoch [13/20], Loss: 1.1795\n",
            "Epoch [14/20], Loss: 1.0986\n",
            "Epoch [15/20], Loss: 1.1190\n",
            "Epoch [16/20], Loss: 1.1245\n",
            "Epoch [17/20], Loss: 1.1201\n",
            "Epoch [18/20], Loss: 1.0844\n",
            "Epoch [19/20], Loss: 1.0687\n",
            "Epoch [20/20], Loss: 1.0933\n",
            "PyTorch: 2. Transformer:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.40      0.33      0.36         6\n",
            "           2       0.46      0.75      0.57         8\n",
            "           3       1.00      0.50      0.67         4\n",
            "\n",
            "    accuracy                           0.50        20\n",
            "   macro avg       0.47      0.40      0.40        20\n",
            "weighted avg       0.50      0.50      0.47        20\n",
            "\n",
            "Training model: CNN\n",
            "Epoch [1/20], Loss: 1.3725\n",
            "Epoch [2/20], Loss: 1.3509\n",
            "Epoch [3/20], Loss: 1.3487\n",
            "Epoch [4/20], Loss: 1.3307\n",
            "Epoch [5/20], Loss: 1.3163\n",
            "Epoch [6/20], Loss: 1.3191\n",
            "Epoch [7/20], Loss: 1.3045\n",
            "Epoch [8/20], Loss: 1.3022\n",
            "Epoch [9/20], Loss: 1.2973\n",
            "Epoch [10/20], Loss: 1.2810\n",
            "Epoch [11/20], Loss: 1.2691\n",
            "Epoch [12/20], Loss: 1.2409\n",
            "Epoch [13/20], Loss: 1.2530\n",
            "Epoch [14/20], Loss: 1.2536\n",
            "Epoch [15/20], Loss: 1.2411\n",
            "Epoch [16/20], Loss: 1.2380\n",
            "Epoch [17/20], Loss: 1.2230\n",
            "Epoch [18/20], Loss: 1.2259\n",
            "Epoch [19/20], Loss: 1.2263\n",
            "Epoch [20/20], Loss: 1.2037\n",
            "PyTorch: 2. CNN:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.60      1.00      0.75         6\n",
            "           2       1.00      0.38      0.55         8\n",
            "           3       0.29      0.50      0.36         4\n",
            "\n",
            "    accuracy                           0.55        20\n",
            "   macro avg       0.47      0.47      0.41        20\n",
            "weighted avg       0.64      0.55      0.52        20\n",
            "\n",
            "PyTorch: 2. Comparison\n",
            "                     accuracy  precision  recall        F1\n",
            "Logistic Regression      0.15   0.066667    0.15  0.090000\n",
            "Feedforward NN           0.35   0.234615    0.35  0.278571\n",
            "Deeper NN                0.40   0.523810    0.40  0.358442\n",
            "RNN (LSTM)               0.50   0.348485    0.50  0.410526\n",
            "Transformer              0.50   0.504615    0.50  0.470996\n",
            "CNN                      0.55   0.637143    0.55  0.515909\n",
            "\n",
            "Training model: Logistic Regression\n",
            "Epoch [1/20], Loss: 1.7543\n",
            "Epoch [2/20], Loss: 1.6277\n",
            "Epoch [3/20], Loss: 1.5281\n",
            "Epoch [4/20], Loss: 1.4492\n",
            "Epoch [5/20], Loss: 1.3866\n",
            "Epoch [6/20], Loss: 1.3301\n",
            "Epoch [7/20], Loss: 1.2813\n",
            "Epoch [8/20], Loss: 1.2362\n",
            "Epoch [9/20], Loss: 1.1938\n",
            "Epoch [10/20], Loss: 1.1540\n",
            "Epoch [11/20], Loss: 1.1152\n",
            "Epoch [12/20], Loss: 1.0775\n",
            "Epoch [13/20], Loss: 1.0416\n",
            "Epoch [14/20], Loss: 1.0062\n",
            "Epoch [15/20], Loss: 0.9718\n",
            "Epoch [16/20], Loss: 0.9390\n",
            "Epoch [17/20], Loss: 0.9068\n",
            "Epoch [18/20], Loss: 0.8757\n",
            "Epoch [19/20], Loss: 0.8464\n",
            "Epoch [20/20], Loss: 0.8186\n",
            "PyTorch: 3. Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.69      0.73        16\n",
            "           1       0.85      1.00      0.92        57\n",
            "           2       0.75      0.86      0.80        69\n",
            "           3       0.39      0.28      0.33        25\n",
            "           4       0.73      0.48      0.58        33\n",
            "\n",
            "    accuracy                           0.75       200\n",
            "   macro avg       0.70      0.66      0.67       200\n",
            "weighted avg       0.73      0.75      0.73       200\n",
            "\n",
            "Training model: Feedforward NN\n",
            "Epoch [1/20], Loss: 1.6547\n",
            "Epoch [2/20], Loss: 1.5157\n",
            "Epoch [3/20], Loss: 1.4160\n",
            "Epoch [4/20], Loss: 1.3226\n",
            "Epoch [5/20], Loss: 1.2200\n",
            "Epoch [6/20], Loss: 1.1089\n",
            "Epoch [7/20], Loss: 0.9940\n",
            "Epoch [8/20], Loss: 0.8886\n",
            "Epoch [9/20], Loss: 0.7980\n",
            "Epoch [10/20], Loss: 0.7235\n",
            "Epoch [11/20], Loss: 0.6644\n",
            "Epoch [12/20], Loss: 0.6125\n",
            "Epoch [13/20], Loss: 0.5681\n",
            "Epoch [14/20], Loss: 0.5257\n",
            "Epoch [15/20], Loss: 0.4886\n",
            "Epoch [16/20], Loss: 0.4520\n",
            "Epoch [17/20], Loss: 0.4180\n",
            "Epoch [18/20], Loss: 0.3834\n",
            "Epoch [19/20], Loss: 0.3500\n",
            "Epoch [20/20], Loss: 0.3187\n",
            "PyTorch: 3. Feedforward NN:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.69      0.79        16\n",
            "           1       1.00      1.00      1.00        57\n",
            "           2       0.93      0.97      0.95        69\n",
            "           3       0.71      0.80      0.75        25\n",
            "           4       0.77      0.73      0.75        33\n",
            "\n",
            "    accuracy                           0.90       200\n",
            "   macro avg       0.87      0.84      0.85       200\n",
            "weighted avg       0.90      0.90      0.89       200\n",
            "\n",
            "Training model: Deeper NN\n",
            "Epoch [1/20], Loss: 1.5994\n",
            "Epoch [2/20], Loss: 1.4820\n",
            "Epoch [3/20], Loss: 1.3543\n",
            "Epoch [4/20], Loss: 1.2140\n",
            "Epoch [5/20], Loss: 1.0571\n",
            "Epoch [6/20], Loss: 0.9164\n",
            "Epoch [7/20], Loss: 0.7978\n",
            "Epoch [8/20], Loss: 0.6954\n",
            "Epoch [9/20], Loss: 0.6038\n",
            "Epoch [10/20], Loss: 0.5192\n",
            "Epoch [11/20], Loss: 0.4403\n",
            "Epoch [12/20], Loss: 0.3661\n",
            "Epoch [13/20], Loss: 0.3004\n",
            "Epoch [14/20], Loss: 0.2395\n",
            "Epoch [15/20], Loss: 0.1903\n",
            "Epoch [16/20], Loss: 0.1552\n",
            "Epoch [17/20], Loss: 0.1260\n",
            "Epoch [18/20], Loss: 0.1034\n",
            "Epoch [19/20], Loss: 0.0871\n",
            "Epoch [20/20], Loss: 0.0744\n",
            "PyTorch: 3. Deeper NN:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.88      0.90        16\n",
            "           1       1.00      1.00      1.00        57\n",
            "           2       1.00      1.00      1.00        69\n",
            "           3       0.96      1.00      0.98        25\n",
            "           4       0.97      0.97      0.97        33\n",
            "\n",
            "    accuracy                           0.98       200\n",
            "   macro avg       0.97      0.97      0.97       200\n",
            "weighted avg       0.98      0.98      0.98       200\n",
            "\n",
            "Training model: RNN (LSTM)\n",
            "Epoch [1/20], Loss: 1.5922\n",
            "Epoch [2/20], Loss: 1.5395\n",
            "Epoch [3/20], Loss: 1.4770\n",
            "Epoch [4/20], Loss: 1.3905\n",
            "Epoch [5/20], Loss: 1.2754\n",
            "Epoch [6/20], Loss: 1.1185\n",
            "Epoch [7/20], Loss: 0.9523\n",
            "Epoch [8/20], Loss: 0.8257\n",
            "Epoch [9/20], Loss: 0.7455\n",
            "Epoch [10/20], Loss: 0.6896\n",
            "Epoch [11/20], Loss: 0.6406\n",
            "Epoch [12/20], Loss: 0.5940\n",
            "Epoch [13/20], Loss: 0.5441\n",
            "Epoch [14/20], Loss: 0.4928\n",
            "Epoch [15/20], Loss: 0.4409\n",
            "Epoch [16/20], Loss: 0.3882\n",
            "Epoch [17/20], Loss: 0.3344\n",
            "Epoch [18/20], Loss: 0.2838\n",
            "Epoch [19/20], Loss: 0.2412\n",
            "Epoch [20/20], Loss: 0.2050\n",
            "PyTorch: 3. RNN (LSTM):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.69      0.81        16\n",
            "           1       1.00      1.00      1.00        57\n",
            "           2       1.00      1.00      1.00        69\n",
            "           3       0.77      0.92      0.84        25\n",
            "           4       0.82      0.82      0.82        33\n",
            "\n",
            "    accuracy                           0.94       200\n",
            "   macro avg       0.92      0.89      0.89       200\n",
            "weighted avg       0.94      0.94      0.93       200\n",
            "\n",
            "Training model: Transformer\n",
            "Epoch [1/20], Loss: 1.7451\n",
            "Epoch [2/20], Loss: 1.4913\n",
            "Epoch [3/20], Loss: 1.4216\n",
            "Epoch [4/20], Loss: 1.3771\n",
            "Epoch [5/20], Loss: 1.3258\n",
            "Epoch [6/20], Loss: 1.2573\n",
            "Epoch [7/20], Loss: 1.1894\n",
            "Epoch [8/20], Loss: 1.0634\n",
            "Epoch [9/20], Loss: 0.9548\n",
            "Epoch [10/20], Loss: 0.8753\n",
            "Epoch [11/20], Loss: 0.8108\n",
            "Epoch [12/20], Loss: 0.7660\n",
            "Epoch [13/20], Loss: 0.7354\n",
            "Epoch [14/20], Loss: 0.6770\n",
            "Epoch [15/20], Loss: 0.6394\n",
            "Epoch [16/20], Loss: 0.6287\n",
            "Epoch [17/20], Loss: 0.5993\n",
            "Epoch [18/20], Loss: 0.5872\n",
            "Epoch [19/20], Loss: 0.5467\n",
            "Epoch [20/20], Loss: 0.5159\n",
            "PyTorch: 3. Transformer:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.69      0.71        16\n",
            "           1       1.00      1.00      1.00        57\n",
            "           2       0.85      0.81      0.83        69\n",
            "           3       0.52      0.60      0.56        25\n",
            "           4       0.64      0.64      0.64        33\n",
            "\n",
            "    accuracy                           0.80       200\n",
            "   macro avg       0.75      0.75      0.75       200\n",
            "weighted avg       0.81      0.80      0.80       200\n",
            "\n",
            "Training model: CNN\n",
            "Epoch [1/20], Loss: 1.5717\n",
            "Epoch [2/20], Loss: 1.4838\n",
            "Epoch [3/20], Loss: 1.4086\n",
            "Epoch [4/20], Loss: 1.3390\n",
            "Epoch [5/20], Loss: 1.2653\n",
            "Epoch [6/20], Loss: 1.1868\n",
            "Epoch [7/20], Loss: 1.1031\n",
            "Epoch [8/20], Loss: 1.0187\n",
            "Epoch [9/20], Loss: 0.9355\n",
            "Epoch [10/20], Loss: 0.8559\n",
            "Epoch [11/20], Loss: 0.7786\n",
            "Epoch [12/20], Loss: 0.7048\n",
            "Epoch [13/20], Loss: 0.6355\n",
            "Epoch [14/20], Loss: 0.5724\n",
            "Epoch [15/20], Loss: 0.5117\n",
            "Epoch [16/20], Loss: 0.4564\n",
            "Epoch [17/20], Loss: 0.4052\n",
            "Epoch [18/20], Loss: 0.3610\n",
            "Epoch [19/20], Loss: 0.3214\n",
            "Epoch [20/20], Loss: 0.2856\n",
            "PyTorch: 3. CNN:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.94      0.91        16\n",
            "           1       1.00      1.00      1.00        57\n",
            "           2       0.94      0.94      0.94        69\n",
            "           3       0.77      0.92      0.84        25\n",
            "           4       0.96      0.79      0.87        33\n",
            "\n",
            "    accuracy                           0.93       200\n",
            "   macro avg       0.91      0.92      0.91       200\n",
            "weighted avg       0.94      0.93      0.93       200\n",
            "\n",
            "PyTorch: 3. Comparison\n",
            "                     accuracy  precision  recall        F1\n",
            "Logistic Regression     0.750   0.731589   0.750  0.732448\n",
            "Feedforward NN          0.895   0.896403   0.895  0.893819\n",
            "Deeper NN               0.985   0.984859   0.985  0.984807\n",
            "RNN (LSTM)              0.935   0.940833   0.935  0.934731\n",
            "Transformer             0.800   0.806049   0.800  0.802441\n",
            "CNN                     0.930   0.935310   0.930  0.930273\n",
            "\n",
            "Training model: Logistic Regression\n",
            "Epoch [1/20], Loss: 1.4822\n",
            "Epoch [2/20], Loss: 1.0111\n",
            "Epoch [3/20], Loss: 0.8039\n",
            "Epoch [4/20], Loss: 0.7086\n",
            "Epoch [5/20], Loss: 0.6547\n",
            "Epoch [6/20], Loss: 0.6221\n",
            "Epoch [7/20], Loss: 0.6033\n",
            "Epoch [8/20], Loss: 0.5924\n",
            "Epoch [9/20], Loss: 0.5854\n",
            "Epoch [10/20], Loss: 0.5806\n",
            "Epoch [11/20], Loss: 0.5770\n",
            "Epoch [12/20], Loss: 0.5746\n",
            "Epoch [13/20], Loss: 0.5719\n",
            "Epoch [14/20], Loss: 0.5701\n",
            "Epoch [15/20], Loss: 0.5689\n",
            "Epoch [16/20], Loss: 0.5678\n",
            "Epoch [17/20], Loss: 0.5664\n",
            "Epoch [18/20], Loss: 0.5656\n",
            "Epoch [19/20], Loss: 0.5650\n",
            "Epoch [20/20], Loss: 0.5643\n",
            "PyTorch: 4. Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.64      0.69        42\n",
            "           1       1.00      1.00      1.00       635\n",
            "           2       0.68      0.82      0.75       629\n",
            "           3       0.70      0.66      0.68       301\n",
            "           4       0.52      0.46      0.49       180\n",
            "           5       0.58      0.35      0.44       213\n",
            "\n",
            "    accuracy                           0.77      2000\n",
            "   macro avg       0.71      0.66      0.67      2000\n",
            "weighted avg       0.76      0.77      0.76      2000\n",
            "\n",
            "Training model: Feedforward NN\n",
            "Epoch [1/20], Loss: 1.3267\n",
            "Epoch [2/20], Loss: 0.8097\n",
            "Epoch [3/20], Loss: 0.4157\n",
            "Epoch [4/20], Loss: 0.2036\n",
            "Epoch [5/20], Loss: 0.1116\n",
            "Epoch [6/20], Loss: 0.0703\n",
            "Epoch [7/20], Loss: 0.0493\n",
            "Epoch [8/20], Loss: 0.0359\n",
            "Epoch [9/20], Loss: 0.0267\n",
            "Epoch [10/20], Loss: 0.0197\n",
            "Epoch [11/20], Loss: 0.0150\n",
            "Epoch [12/20], Loss: 0.0115\n",
            "Epoch [13/20], Loss: 0.0087\n",
            "Epoch [14/20], Loss: 0.0067\n",
            "Epoch [15/20], Loss: 0.0054\n",
            "Epoch [16/20], Loss: 0.0044\n",
            "Epoch [17/20], Loss: 0.0034\n",
            "Epoch [18/20], Loss: 0.0028\n",
            "Epoch [19/20], Loss: 0.0022\n",
            "Epoch [20/20], Loss: 0.0018\n",
            "PyTorch: 4. Feedforward NN:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      1.00      1.00       635\n",
            "           2       1.00      1.00      1.00       629\n",
            "           3       1.00      1.00      1.00       301\n",
            "           4       1.00      1.00      1.00       180\n",
            "           5       1.00      1.00      1.00       213\n",
            "\n",
            "    accuracy                           1.00      2000\n",
            "   macro avg       1.00      1.00      1.00      2000\n",
            "weighted avg       1.00      1.00      1.00      2000\n",
            "\n",
            "Training model: Deeper NN\n",
            "Epoch [1/20], Loss: 1.2353\n",
            "Epoch [2/20], Loss: 0.5618\n",
            "Epoch [3/20], Loss: 0.2453\n",
            "Epoch [4/20], Loss: 0.1249\n",
            "Epoch [5/20], Loss: 0.0579\n",
            "Epoch [6/20], Loss: 0.0270\n",
            "Epoch [7/20], Loss: 0.0151\n",
            "Epoch [8/20], Loss: 0.0094\n",
            "Epoch [9/20], Loss: 0.0063\n",
            "Epoch [10/20], Loss: 0.0045\n",
            "Epoch [11/20], Loss: 0.0031\n",
            "Epoch [12/20], Loss: 0.0021\n",
            "Epoch [13/20], Loss: 0.0014\n",
            "Epoch [14/20], Loss: 0.0010\n",
            "Epoch [15/20], Loss: 0.0007\n",
            "Epoch [16/20], Loss: 0.0005\n",
            "Epoch [17/20], Loss: 0.0004\n",
            "Epoch [18/20], Loss: 0.0003\n",
            "Epoch [19/20], Loss: 0.0003\n",
            "Epoch [20/20], Loss: 0.0002\n",
            "PyTorch: 4. Deeper NN:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      1.00      1.00       635\n",
            "           2       1.00      1.00      1.00       629\n",
            "           3       1.00      1.00      1.00       301\n",
            "           4       1.00      1.00      1.00       180\n",
            "           5       1.00      1.00      1.00       213\n",
            "\n",
            "    accuracy                           1.00      2000\n",
            "   macro avg       1.00      1.00      1.00      2000\n",
            "weighted avg       1.00      1.00      1.00      2000\n",
            "\n",
            "Training model: RNN (LSTM)\n",
            "Epoch [1/20], Loss: 1.3561\n",
            "Epoch [2/20], Loss: 0.6456\n",
            "Epoch [3/20], Loss: 0.3873\n",
            "Epoch [4/20], Loss: 0.2568\n",
            "Epoch [5/20], Loss: 0.1657\n",
            "Epoch [6/20], Loss: 0.1046\n",
            "Epoch [7/20], Loss: 0.0681\n",
            "Epoch [8/20], Loss: 0.0477\n",
            "Epoch [9/20], Loss: 0.0343\n",
            "Epoch [10/20], Loss: 0.0249\n",
            "Epoch [11/20], Loss: 0.0186\n",
            "Epoch [12/20], Loss: 0.0142\n",
            "Epoch [13/20], Loss: 0.0112\n",
            "Epoch [14/20], Loss: 0.0087\n",
            "Epoch [15/20], Loss: 0.0069\n",
            "Epoch [16/20], Loss: 0.0056\n",
            "Epoch [17/20], Loss: 0.0045\n",
            "Epoch [18/20], Loss: 0.0037\n",
            "Epoch [19/20], Loss: 0.0031\n",
            "Epoch [20/20], Loss: 0.0025\n",
            "PyTorch: 4. RNN (LSTM):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      1.00      1.00       635\n",
            "           2       1.00      1.00      1.00       629\n",
            "           3       1.00      1.00      1.00       301\n",
            "           4       1.00      1.00      1.00       180\n",
            "           5       1.00      1.00      1.00       213\n",
            "\n",
            "    accuracy                           1.00      2000\n",
            "   macro avg       1.00      1.00      1.00      2000\n",
            "weighted avg       1.00      1.00      1.00      2000\n",
            "\n",
            "Training model: Transformer\n",
            "Epoch [1/20], Loss: 1.3369\n",
            "Epoch [2/20], Loss: 0.7912\n",
            "Epoch [3/20], Loss: 0.6511\n",
            "Epoch [4/20], Loss: 0.5409\n",
            "Epoch [5/20], Loss: 0.4194\n",
            "Epoch [6/20], Loss: 0.3367\n",
            "Epoch [7/20], Loss: 0.2841\n",
            "Epoch [8/20], Loss: 0.2392\n",
            "Epoch [9/20], Loss: 0.2152\n",
            "Epoch [10/20], Loss: 0.1961\n",
            "Epoch [11/20], Loss: 0.1750\n",
            "Epoch [12/20], Loss: 0.1596\n",
            "Epoch [13/20], Loss: 0.1410\n",
            "Epoch [14/20], Loss: 0.1296\n",
            "Epoch [15/20], Loss: 0.1248\n",
            "Epoch [16/20], Loss: 0.1137\n",
            "Epoch [17/20], Loss: 0.1049\n",
            "Epoch [18/20], Loss: 0.0998\n",
            "Epoch [19/20], Loss: 0.0896\n",
            "Epoch [20/20], Loss: 0.0839\n",
            "PyTorch: 4. Transformer:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      1.00      1.00       635\n",
            "           2       1.00      1.00      1.00       629\n",
            "           3       1.00      1.00      1.00       301\n",
            "           4       0.98      0.98      0.98       180\n",
            "           5       0.99      0.99      0.99       213\n",
            "\n",
            "    accuracy                           1.00      2000\n",
            "   macro avg       0.99      0.99      0.99      2000\n",
            "weighted avg       1.00      1.00      1.00      2000\n",
            "\n",
            "Training model: CNN\n",
            "Epoch [1/20], Loss: 1.4306\n",
            "Epoch [2/20], Loss: 0.8301\n",
            "Epoch [3/20], Loss: 0.4712\n",
            "Epoch [4/20], Loss: 0.2538\n",
            "Epoch [5/20], Loss: 0.1189\n",
            "Epoch [6/20], Loss: 0.0630\n",
            "Epoch [7/20], Loss: 0.0396\n",
            "Epoch [8/20], Loss: 0.0288\n",
            "Epoch [9/20], Loss: 0.0226\n",
            "Epoch [10/20], Loss: 0.0183\n",
            "Epoch [11/20], Loss: 0.0157\n",
            "Epoch [12/20], Loss: 0.0134\n",
            "Epoch [13/20], Loss: 0.0117\n",
            "Epoch [14/20], Loss: 0.0104\n",
            "Epoch [15/20], Loss: 0.0089\n",
            "Epoch [16/20], Loss: 0.0076\n",
            "Epoch [17/20], Loss: 0.0066\n",
            "Epoch [18/20], Loss: 0.0057\n",
            "Epoch [19/20], Loss: 0.0047\n",
            "Epoch [20/20], Loss: 0.0037\n",
            "PyTorch: 4. CNN:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        42\n",
            "           1       1.00      1.00      1.00       635\n",
            "           2       1.00      1.00      1.00       629\n",
            "           3       1.00      1.00      1.00       301\n",
            "           4       1.00      1.00      1.00       180\n",
            "           5       1.00      1.00      1.00       213\n",
            "\n",
            "    accuracy                           1.00      2000\n",
            "   macro avg       1.00      1.00      1.00      2000\n",
            "weighted avg       1.00      1.00      1.00      2000\n",
            "\n",
            "PyTorch: 4. Comparison\n",
            "                     accuracy  precision  recall       F1\n",
            "Logistic Regression    0.7685   0.762647  0.7685  0.76038\n",
            "Feedforward NN         1.0000   1.000000  1.0000  1.00000\n",
            "Deeper NN              1.0000   1.000000  1.0000  1.00000\n",
            "RNN (LSTM)             1.0000   1.000000  1.0000  1.00000\n",
            "Transformer            0.9970   0.997000  0.9970  0.99700\n",
            "CNN                    1.0000   1.000000  1.0000  1.00000\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}