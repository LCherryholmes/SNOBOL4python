{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive, files\n",
        "drive.mount(\"/content/drive\")\n",
        "drive_path = \"/content/drive/My Drive/CSCI-576\""
      ],
      "metadata": {
        "id": "FQ_jQaZnUy6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjJqIg9JQbou"
      },
      "outputs": [],
      "source": [
        "def read_image(filename):\n",
        "    img = cv2.imread(f\"{drive_path}/{filename}\", cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(f\"File not found: {drive_path}/{filename}\")\n",
        "    assert img.dtype == np.uint8\n",
        "    return img.astype(np.float32) / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def write_image(M, filename):\n",
        "    if M.ndim != 2:\n",
        "        raise ValueError(\"Matrix must be 2-dimensional\")\n",
        "    img = np.clip(M, 0.0, 1.0) * 255.0\n",
        "    img = img.astype(np.uint8)\n",
        "    if not cv2.imwrite(f\"{drive_path}/{filename}\", img): #, cv2.IMWRITE_JPEG_QUALITY, 100\n",
        "        raise IOError(f\"Error writing to file {drive_path}/{filename}\")"
      ],
      "metadata": {
        "id": "cZFYnjjsxhla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image(M, title):\n",
        "    ROWS, COLUMNS = M.shape\n",
        "    if M.ndim != 2:\n",
        "        raise ValueError(\"Matrix must be 2-dimensional\")\n",
        "    img = np.clip(M, 0.0, 1.0)\n",
        "    plt.figure(figsize=(ROWS / 128, COLUMNS / 128), dpi=128)\n",
        "    plt.imshow(img, cmap='gray', vmin=0.0, vmax=1.0)\n",
        "    if title: plt.title(f\"{title} {ROWS}x{COLUMNS}\")\n",
        "    else: plt.title(f\"{ROWS}x{COLUMNS}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "S1RWh4nixh0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "image_names = [\n",
        "    \"grayMan\"\n",
        "  , \"grayMan_gaussian\"\n",
        "  , \"grayMan_saltandpepper\"\n",
        "  , \"Q4_original\"\n",
        "  , \"Q4_corrupted\"\n",
        "]\n",
        "for name in image_names:\n",
        "    M = read_image(f\"{name}.png\")\n",
        "    print(M.shape)"
      ],
      "metadata": {
        "id": "BmYASMa_VLjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 1\n",
        "#-------------------------------------------------------------------------------\n",
        "M = read_image(\"grayMan.png\")\n",
        "ROWS, COLUMNS = M.shape\n",
        "R = -1\n",
        "while R < 0 or R > ROWS:\n",
        "    try: R = int(input(f\"Number of rows up to {ROWS}:\")) # <== input 204\n",
        "    except: pass\n",
        "C = -1\n",
        "while C < 0 or C > COLUMNS:\n",
        "    try: C = int(input(f\"Number of columns up to {COLUMNS}: \")) # <== input 306\n",
        "    except: pass\n",
        "rows = np.random.choice(np.arange(0, ROWS), size=R, replace=False)\n",
        "columns = np.random.choice(np.arange(0, COLUMNS), size=C, replace=False)\n",
        "S = M\n",
        "S = np.delete(S, rows, axis=0)\n",
        "S = np.delete(S, columns, axis=1)\n",
        "display_image(M, f\"Original\")\n",
        "display_image(S, f\"Sliced Up!\")\n",
        "write_image(S, f\"grayMan_1.jpg\")"
      ],
      "metadata": {
        "id": "4BU9k-mHnyrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 2\n",
        "def correlation(img, transform):\n",
        "    padded = np.pad(img, pad_width=1, mode='edge')\n",
        "    output = np.zeros_like(img)\n",
        "    for r in range(ROWS):\n",
        "        for c in range(COLUMNS):\n",
        "            output[r, c] = transform(padded, r, c)\n",
        "    return output"
      ],
      "metadata": {
        "id": "9abONJ1Ye8cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 2\n",
        "laplacian_kernel      = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
        "mega_laplacian_kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
        "average_kernel        = np.array([[1/9, 1/9, 1/9], [1/9, 1/9, 1/9], [1/9, 1/9, 1/9]])\n",
        "sobel_x_kernel        = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
        "sobel_y_kernel        = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
        "if True:\n",
        "    from scipy.signal import medfilt2d\n",
        "    from scipy.signal import correlate2d\n",
        "    def median_smoothing_filter(I):     return medfilt2d(I, kernel_size=3)\n",
        "    def average_smoothing_filter(I):    return correlate2d(I, average_kernel,   mode='same', boundary='symm').clip(0.0, 1.0)\n",
        "    def laplacian_sharpening_filter(I): return correlate2d(I, laplacian_kernel, mode='same', boundary='symm').clip(0.0, 1.0)\n",
        "    def mega_laplacian_filter(I):       return correlate2d(I, mega_laplacian_kernel,  mode='same', boundary='symm').clip(0.0, 1.0)\n",
        "    def sobel_x_filter(I):              return correlate2d(I, sobel_x_kernel,   mode='same', boundary='symm').clip(0.0, 1.0)\n",
        "    def sobel_y_filter(I):              return correlate2d(I, sobel_y_kernel,   mode='same', boundary='symm').clip(0.0, 1.0)\n",
        "else:\n",
        "    def median_smoothing_filter(I):     return correlation(I, lambda I, r, c: np.median(I[r:r+3, c:c+3]))\n",
        "    def average_smoothing_filter(I):    return correlation(I, lambda I, r, c: np.sum(I[r:r+3, c:c+3] * average_kernel)).clip(0.0, 1.0)\n",
        "    def laplacian_sharpening_filter(I): return correlation(I, lambda I, r, c: np.sum(I[r:r+3, c:c+3] * laplacian_kernel)).clip(0.0, 1.0)\n",
        "    def mega_laplacian_filter(I):       return correlation(I, lambda I, r, c: np.sum(I[r:r+3, c:c+3] * mega_laplacian_kernel)).clip(0.0, 1.0)\n",
        "    def sobel_x_filter(I):              return correlation(I, lambda I, r, c: np.sum(I[r:r+3, c:c+3] * sobel_x_kernel)).clip(0.0, 1.0)\n",
        "    def sobel_y_filter(I):              return correlation(I, lambda I, r, c: np.sum(I[r:r+3, c:c+3] * sobel_y_kernel)).clip(0.0, 1.0)"
      ],
      "metadata": {
        "id": "P0r-YMvSIntk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 2\n",
        "#-------------------------------------------------------------------------------\n",
        "names = {\"grayMan_gaussian\": 'g', \"grayMan_saltandpepper\": 'sb'}\n",
        "for name in names:\n",
        "    original      = read_image(f\"{name}.png\")\n",
        "    avg_smooth    = average_smoothing_filter(original)\n",
        "    avg_laplacian = laplacian_sharpening_filter(avg_smooth)\n",
        "    med_smooth    = median_smoothing_filter(original)\n",
        "    med_laplacian = laplacian_sharpening_filter(med_smooth)\n",
        "    display_image(original,       f\"Original {name}\")\n",
        "    display_image(avg_smooth,     f\"Avg smoothing {name}\")\n",
        "    display_image(avg_laplacian,  f\"Avg smooth+laplacian {name}\")\n",
        "    display_image(med_smooth,     f\"Median smoothing {name}\")\n",
        "    display_image(med_laplacian,  f\"Median smooth+laplacian {name}\")\n",
        "    write_image(avg_smooth,       f\"fnA{names[name]}.jpg\")\n",
        "    write_image(avg_laplacian,    f\"fnA{names[name]}L.jpg\")\n",
        "    write_image(med_smooth,       f\"fnM{names[name]}.jpg\")\n",
        "    write_image(med_laplacian,    f\"fnM{names[name]}L.jpg\")"
      ],
      "metadata": {
        "id": "j7dBmk4u2BNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparison\n",
        "#   average smoothing works nicely with gaussian noise, but not at all with impulse noise\n",
        "#   Laplacian with smoothed gaussian noise brings back detail but also brings back the noise\n",
        "#   median smoothing also works well with gaussian noise, hard to tell which is better\n",
        "#   median smoothing works very nicely with impulse noise\n",
        "#   Laplacian with smoothed impulse noise looks very nice"
      ],
      "metadata": {
        "id": "xrVJCr8qcAje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3\n",
        "def histogram_display(hist):\n",
        "    bins = np.arange(256)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.bar(bins, hist, width=1.0, color='gray', alpha=0.75)\n",
        "    plt.title(\"Histogram\")\n",
        "    plt.xlabel('Intensity')\n",
        "    plt.ylabel('Occurrences')\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "4CUtvCXlQ6eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3\n",
        "def histogram_calculate(img):\n",
        "    hist = [0] * 256\n",
        "    ROWS, COLUMNS = img.shape\n",
        "    for r in range(ROWS):\n",
        "        for c in range(COLUMNS):\n",
        "            assert img[r, c] >= 0.0 and img[r, c] <= 1.0\n",
        "            hist[int(img[r, c] * 255)] += 1\n",
        "    return hist"
      ],
      "metadata": {
        "id": "JZ_j5UlVXpfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3\n",
        "def CDF_calculate(hist):\n",
        "    cdf = [0] * 256\n",
        "    cdf[0] = hist[0]\n",
        "    for i in range(1, 256):\n",
        "        cdf[i] = cdf[i - 1] + hist[i]\n",
        "    return cdf"
      ],
      "metadata": {
        "id": "C2kcI7eGZRC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3\n",
        "def histogram_equalization(img):\n",
        "    ROWS, COLUMNS = img.shape\n",
        "    total = ROWS * COLUMNS\n",
        "    hist = histogram_calculate(img)\n",
        "    cdf = CDF_calculate(hist)\n",
        "    cdf_min = cdf[0]\n",
        "    for i in range(256):\n",
        "        cdf[i] = (cdf[i] - cdf_min) / (total - cdf_min)\n",
        "    out = np.zeros_like(img)\n",
        "    for i in range(ROWS):\n",
        "        for j in range(COLUMNS):\n",
        "            out[i, j] = cdf[int(img[i, j] * 255)]\n",
        "    return out"
      ],
      "metadata": {
        "id": "xd3TrfiLWpxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3\n",
        "def power_transform(x, gamma): return x ** gamma\n",
        "def log_transform(x, c): return c * np.log(1.0 + x)\n",
        "def inverse_log_transform(x, c): return c * (np.exp(x) - 1.0)\n",
        "def minmax_stretch_transform(x, min, max): return (x - min) / (max - min)"
      ],
      "metadata": {
        "id": "c5YVhT8D7A_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3(a)\n",
        "#-------------------------------------------------------------------------------\n",
        "# This image was chosen due to having many areas with dark shadows\n",
        "name = \"Forest\"\n",
        "POWER = 0.55\n",
        "original = read_image(\"Q3_forest.png\")\n",
        "output = power_transform(original, POWER)\n",
        "display_image(original, f\"{name} Original\")\n",
        "display_image(output, f\"{name} Power={POWER}\")\n",
        "write_image(output, f\"Q3_forest_3a.png\")"
      ],
      "metadata": {
        "id": "sMJNcJY8DUcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3(b)\n",
        "#-------------------------------------------------------------------------------\n",
        "# First image chosen due to its histogram limited to one region\n",
        "names = [\"Mushrooms\", \"Hawkes Bay\"]\n",
        "filenames = [\"Q3_mushrooms\", \"Q3_unequalized_hawkes_bay_nz\"]\n",
        "extnames = [\"png\", \"jpg\"]\n",
        "for n in range(0, 2): # 0, 2\n",
        "    original = read_image(f\"{filenames[n]}.{extnames[n]}\")\n",
        "    output = histogram_equalization(original)\n",
        "    display_image(original, f\"{names[n]} Original\")\n",
        "    display_image(output, f\"{names[n]} Histogram EQ\")\n",
        "    write_image(output, f\"{filenames[n]}_3b.png\")"
      ],
      "metadata": {
        "id": "ARgfjK1TO_pU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3(c)\n",
        "#-------------------------------------------------------------------------------\n",
        "# First image chosen due to its histogram limited with multiple clusters\n",
        "names = [\"Moon\", \"Misty Mountains\"]\n",
        "filenames = [\"Q3_sphx_glr_plot_scientific_005\", \"Q3_misty_mountains\"]\n",
        "extnames = [\"png\", \"jpg\"]\n",
        "for n in range(0, 2):\n",
        "    if n == 0: XSLIDE, ROW_BLOCKS, COLUMN_BLOCKS = 4, 16, 20\n",
        "    if n == 1: XSLIDE, ROW_BLOCKS, COLUMN_BLOCKS = 4, 16, 24\n",
        "    original = read_image(f\"{filenames[n]}.{extnames[n]}\")\n",
        "    ROWS, COLUMNS = original.shape\n",
        "    display_image(original, f\"{names[n]} Original\")\n",
        "    output = np.zeros_like(original, dtype=np.float32)\n",
        "    weighting = np.zeros_like(original, dtype=np.float32)\n",
        "    accumulator = np.zeros_like(original, dtype=np.float32)\n",
        "    height = ROWS // ROW_BLOCKS\n",
        "    width = COLUMNS // COLUMN_BLOCKS\n",
        "    for r in range(ROW_BLOCKS * XSLIDE):\n",
        "        for c in range(COLUMN_BLOCKS * XSLIDE):\n",
        "            r_start = ((r * height) // XSLIDE); r_end = r_start + height\n",
        "            c_start = ((c * width) // XSLIDE);  c_end = c_start + width\n",
        "            weighting[r_start:r_end, c_start:c_end] += 1.0\n",
        "            accumulator[r_start:r_end, c_start:c_end] += \\\n",
        "                histogram_equalization(original[r_start:r_end, c_start:c_end])\n",
        "    output = accumulator / weighting\n",
        "    display_image(output, f\"{names[n]} Localized Histogram EQ\")\n",
        "    write_image(output, f\"{filenames[n]}_3c.png\")"
      ],
      "metadata": {
        "id": "wfKdJj9Khgqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3(d)\n",
        "#-------------------------------------------------------------------------------\n",
        "# Image chosen since demonstrates a proven technique,\n",
        "# i.e. using logarithm on fourier spectrum\n",
        "name = \"Spectrum\"\n",
        "original = read_image(\"Q3_spectrum.png\")\n",
        "output = log_transform(original, 4.0)\n",
        "display_image(original, f\"{name} Original\")\n",
        "display_image(output, f\"{name} Logarithm\")\n",
        "write_image(output, \"Q3_spectrum_3d.png\")"
      ],
      "metadata": {
        "id": "-XzZxxFSKO0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3(e)\n",
        "#-------------------------------------------------------------------------------\n",
        "# Image chosen since it had narrow range of intensities to expand\n",
        "name = \"Bread Rolls\"\n",
        "original = read_image(\"Q3_bread rolls.png\")\n",
        "output = minmax_stretch_transform(original, np.min(original), np.max(original))\n",
        "display_image(original, f\"{name} Original\")\n",
        "display_image(output, f\"{name} Linear Contrast Stretch\")\n",
        "write_image(output, \"Q3_bread rolls_3e.png\")"
      ],
      "metadata": {
        "id": "Ng5jQuyrcpev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 4\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "def compare_images(original, restored):\n",
        "    if original.shape != restored.shape:\n",
        "        raise ValueError(f\"Mismatched shapes: {original.shape} != {restored.shape}\")\n",
        "    data_range = original.max() - original.min()\n",
        "    if data_range == 0: data_range = 255.0\n",
        "    mse = np.mean((original - restored) ** 2)\n",
        "    if mse == 0: psnr = float('inf')\n",
        "    else: psnr = 20 * np.log10(data_range) - 10 * np.log10(mse)\n",
        "    ssim_metric, diff_map = ssim(original, restored, full=True, data_range=data_range)\n",
        "    print(f\"MSE={mse}\", f\"PSNR={psnr}\", f\"simularity={ssim_metric}\") # , diff_map"
      ],
      "metadata": {
        "id": "YfrFjv7LDN1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 4\n",
        "from scipy.ndimage import gaussian_filter\n",
        "def unsharp_masking(img, radius=1.0, amount=1.0):\n",
        "    blurred = gaussian_filter(img, sigma=radius)\n",
        "    return np.clip(img + amount * (img - blurred), 0.0, 1.0)"
      ],
      "metadata": {
        "id": "wkwJW2HTls5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sobel_sharpening(img, amount=1.0):\n",
        "    sobel_x = sobel_x_filter(img)\n",
        "    sobel_y = sobel_x_filter(img)\n",
        "    edges = np.hypot(sobel_x, sobel_y)\n",
        "    return np.clip(img + amount * edges, 0.0, 1.0)"
      ],
      "metadata": {
        "id": "vyXTm0dRDOo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 4\n",
        "#-------------------------------------------------------------------------------\n",
        "# Possibly necessitates deblurring techniques beyond current scope of class.\n",
        "# The following sequence achieved 0.57 simularity to the original\n",
        "name = \"Q4\"\n",
        "original = read_image(\"Q4_original.png\")\n",
        "corrupted = read_image(\"Q4_corrupted.png\")\n",
        "MIN = np.min(corrupted)\n",
        "MAX = np.max(corrupted)\n",
        "steps = [\n",
        "    (\"3x3\", lambda img: median_smoothing_filter(img)), # Nice\n",
        "#   (\"1x1\", log_transform, 1.0),\n",
        "#   (\"1x1\", power_transform, 0.50),\n",
        "    (\"1x1\", minmax_stretch_transform, MIN, MAX), # Nice\n",
        "#   (\"NxN\", lambda img: histogram_equalization(img)),\n",
        "#   (\"3x3\", lambda img: laplacian_sharpening_filter(img)),\n",
        "#   (\"3x3\", lambda img: mega_laplacian_filter(img)),\n",
        "    (\"NxN\", unsharp_masking, 1.0, 1.0), # tiny help\n",
        "#   (\"NxN\", sobel_sharpening, 2.0),\n",
        "    (\"3x3\", lambda img: average_smoothing_filter(img)), # little help\n",
        "]\n",
        "restored = corrupted\n",
        "for step in steps:\n",
        "#   histogram_display(histogram_calculate(restored))\n",
        "    match step[0]:\n",
        "        case \"1x1\": restored = (step[1])(restored, *step[2:]).clip(0.0, 1.0)\n",
        "        case \"NxN\": restored = (step[1])(restored, *step[2:])\n",
        "        case \"3x3\": restored = (step[1])(restored)\n",
        "compare_images(original, original)\n",
        "compare_images(original, corrupted)\n",
        "compare_images(original, restored)\n",
        "display_image(restored, f\"{name} Restored\")\n",
        "display_image(original, f\"{name} Original\")\n",
        "write_image(restored, \"Q4_corrupted_4.png\")"
      ],
      "metadata": {
        "id": "bH-h7rXjo-IV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}