Concept,Ideas,Tiny Lesson
introduction to image processing,what is image enhancement?,Image enhancement involves algorithms to improve an image’s interpretability by emphasizing features or reducing distortions.
image enhancement,highlight interesting detail,"Techniques like contrast stretching and edge enhancement amplify subtle structures, making features stand out clearly."
image enhancement,remove noise,"Filters such as median or Gaussian smoothing suppress random intensity fluctuations, yielding a cleaner image without sacrificing key details."
image enhancement,make more appealing,Adjustments like histogram equalization and gamma correction refine brightness and contrast to create more visually pleasing images.
spatial & frequency domains,spatial domain techniques,Spatial methods modify pixel values directly using neighborhood operations such as local averaging or morphological transforms.
spatial & frequency domains,frequency domain techniques,"Frequency methods transform the image into the spectral domain (e.g., via Fourier transform), filter desired frequencies, and then reconstruct it."
grey levels,integer or real value,"Pixel intensities can be quantized as discrete integers (e.g., 0–255) or represented with continuous real values, affecting precision and complexity."
spatial domain image enhancement,"g(x0, y0) = T[f(x0, y0)], T defined over neighborhood","This notation describes a general enhancement where the output at (x₀, y₀) is a function T applied to input pixels within a defined neighborhood."
spatial domain image enhancement,"point processing, intensiy transform, neighborhood size is 1x1","Point processing applies a transform T solely to each pixel independently, enabling operations like thresholding and contrast stretching."
spatial domain image enhancement,"spatial filtering, neighborhood size greater than 1x1","Spatial filtering uses windows larger than one pixel (e.g., a 3×3 filter) to perform operations like smoothing or sharpening based on neighborhood values."
intesity transformation,image processing,"Intensity transformations adjust pixel brightness values through direct mapping functions applied to all pixels, altering the overall appearance of the image."
intesity transformation,point processing,"In point processing, each pixel is independently mapped from its original intensity to a new one via a function T, without using any neighboring pixel information."
intesity transformation,negative images,"Negative transforms invert every pixel’s value (s = L–1 – r), turning dark regions light and vice versa, which helps reveal details hidden in shadows."
intesity transformation,thresholding,"Thresholding makes binary an image by assigning pixels below or above a cutoff to two levels, effectively segmenting objects from the background."
intesity transformation,logarithmic transformations,"Log transforms apply s = c·log(1 + r) to compress high-intensity values and expand low-intensity ones, reducing dynamic range while enhancing dark details."
intesity transformation,power law transformations,"Power-law (gamma) transforms use s = c·rᵞ to create nonlinear intensity mappings, where γ controls whether darker (γ < 1) or lighter (γ > 1) regions gain more contrast."
intesity transformation,grey-level slicing,"Grey‐level slicing boosts intensities within a specified range and suppresses others, isolating features of interest by highlighting a target band of grey levels."
intesity transformation,bit plane slicing,Bit‐plane slicing isolates or manipulates specific bits in each pixel’s binary representation (using masks like 0x0100) to analyze or emphasize particular bit‐significance layers.
intesity transformation,"T is grey-level transformation function, point-processing operation","The function T defines how each input intensity r is converted to output s, characterizing any point‐wise transform’s behavior."
intesity transformation,"s = T(r), where r refers to original pixel and s refers to processed pixel","This notation formalizes point processing: for every pixel with intensity r, the output intensity s is computed by applying the transform T."
intesity transformation - negative images,"enhances white or grey detail in dark regions, s = intensity_max - r","Inversion using s = L–1 – r reveals faint structures in darker regions by swapping light and dark values, boosting visibility of subtle details."
intesity transformation - thresholding,"segments and isolates object from background, s = 0 if r <= threshold, s = 1 if r > threshold","By mapping all pixels below a threshold T to 0 and above T to 1, thresholding cleanly separates foreground objects from their background."
intesity transformation - basic grey-level,"linear, negative or identity","Basic grey‐level transforms include identity (s = r), linear scaling (s = a·r + b), and negative inversion, serving as foundational contrast adjustments."
intesity transformation - basic grey-level,"logarithmic, logarithm or inverse logarithm","Log and inverse‐log functions reshape intensity distributions for dynamic range compression or expansion, revealing details in specific ranges."
intesity transformation - basic grey-level,"power law, nth power, nth root",Power‐law transforms (s = rⁿ or r^(1/n)) enable flexible contrast control by emphasizing darker or lighter regions depending on the exponent n.
intesity transformation - logarithmic,"s = c * log(1 + r), c is usually 1","This form ensures zero input maps to zero output and scales other intensities logarithmically, amplifying small values and compressing large ones."
intesity transformation - logarithmic,expands values of dark pixels while compressing lighter pixels,"The steep slope of the log curve near zero enhances subtle low‐level details, while its flatter tail suppresses extreme highlights."
intesity transformation - logarithmic,"useful when have a large range of grey level values, compresses the dynamic range","Log transforms tame wide‐ranging intensities into a narrower display range, making visualization of both shadows and highlights more manageable."
intesity transformation - logarithmic,useful after a fourier transform to reveal more detail,Applying a log scale to the magnitude spectrum highlights weaker frequency components that would otherwise be masked by dominant peaks.
intesity transformation - power law,"s = c * r ** γ, c is usually 1","Gamma correction uses this formula to nonlinearly adjust brightness: c sets scale, while γ shapes whether dark or bright tones are emphasized."
intesity transformation - power law,"γ < 1.0 to increase darker contrast, compress lighter, like 0.2","When γ is less than 1, the mapping curve lifts low intensities more than high ones, unveiling detail in shadow regions at the cost of highlight contrast."
intesity transformation - power law,"γ > 1.0 to increase lighter contrast, compress darker, like 5.0","A γ greater than 1 steepens the mapping for high intensities, boosting highlights while flattening shadow detail, useful for bright‐feature analysis."
intesity transformation - piecewise-linear,s = r * envelope?,"Piecewise‐linear transforms define multiple linear segments (an “envelope”) over intensity ranges, enabling targeted contrast stretching or thresholding in each segment."
intesity transformation - bit-plane slicing,"s = r & bit_mask, 0x1000, 0x0100, 0x0010, 0x0001","Masking a specific bit plane (e.g., 0x0010) extracts that binary layer’s contribution, which can be amplified or suppressed to analyze particular bit‐level details."
intesity transformation - average image,"corrupted image: g(x, y) = f(x, y) + η(x, y)",A noisy observation g combines the true image f with additive noise η; averaging aims to recover f by reducing η’s effect.
intesity transformation - average image,η noise has zero mean value,"Zero‐mean noise implies its fluctuations cancel out over multiple images, making simple averaging an effective de‐noising strategy."
intesity transformation - average image,every pair of points has noise uncorrelated,"Uncorrelated noise samples ensure that averaging K images reduces noise variance by 1/K, since each pixel’s noise contributions don’t reinforce each other."
intesity transformation - average image,average a set of K noisy images,"By summing K independent noisy observations and dividing by K, the signal (true image) remains while noise diminishes by a factor of √K, improving overall image quality."
histogram equalization,image processing,"Histogram equalization redistributes an image’s grey-level frequencies to flatten its histogram, thereby enhancing overall contrast and detail."
histogram equalization,distribution of grey-levels in an image,"The histogram plots pixel counts per intensity level, revealing how tones are distributed from dark through mid-range to bright values."
histogram equalization,"useful in image processing, especially segmentation","By enhancing global contrast, histogram equalization makes objects stand out against the background, improving the accuracy of threshold-based segmentation."
histogram equalization,distribution of dark image,"A dark image’s histogram clusters at low intensities, indicating most pixels are in shadow regions and details there are compressed."
histogram equalization,distribution of bright image,"Bright images show histograms skewed toward high intensities, which can wash out highlights and obscure details in bright areas."
histogram equalization,distribution of low-contrast image,"Low-contrast images have narrow, peaked histograms, meaning pixel values occupy a small intensity range and the image appears flat."
histogram equalization,distribution of high-contrast image,"A high-contrast image displays a broad histogram spanning most intensity levels, giving clear separation between dark and light regions."
histogram equalization,contrast stretching,Contrast stretching linearly maps the existing intensity range to the full display range but doesn’t adapt to actual pixel distributions like histogram equalization does.
histogram equalization,"CDF, cumulative distribution function of a random variable","The CDF at a grey level r sums normalized histogram values up to r, forming the basis of the equalization mapping function."
histogram equalization,"function of input intensity, frequencies of intensity, total number of pixels",The mapping s(r)=⌊(L–1)·∑_{j=0}^r n_j/(M·N)⌋ uses the histogram frequencies n_j and total pixel count M·N to remap each input intensity r to output s.
histogram equalization,example of a 3-bit 64x64 image,"For a 64×64 image with 3-bit pixels (0–7), you compute its 8-bin histogram, derive the CDF, and remap each level so all eight intensities are more evenly used."
histogram equalization,more flexible than specific transformations,"Because it derives its transform from the actual histogram, it adapts automatically to varied lighting and contrast conditions—unlike fixed log or power-law curves."
histogram equalization,does not always work if frequencies are clustered in segregated areas,"If pixel values cluster in distinct intensity bands, equalization can introduce gaps or amplify quantization noise, leading to unnatural tones."
histogram equalization,local histogram processing,"Local equalization (CLAHE) applies the process within sliding windows, boosting contrast adaptively per region while limiting over-amplification in uniform areas."
spatial filtering,image processing,"Spatial filtering replaces each pixel with a function of its local neighborhood, enabling tasks like smoothing, sharpening, and noise reduction directly in the spatial domain."
spatial filtering,neighborhood operations,"Neighborhood operations compute a new pixel value using a defined window (e.g., 3×3) around the target pixel, applying functions such as min, max, or average."
spatial filtering,smoothing operations,"Smoothing filters like mean or median reduce noise by averaging or selecting central values, sacrificing some detail to produce a cleaner image."
spatial filtering,what happens at the edges?,"Edge handling strategies include zero-padding, replicating border pixels, or reflecting the image to ensure neighborhoods are well-defined at the borders."
spatial filtering,convolution,"Convolution flips the kernel both horizontally and vertically, multiplies it element-wise with the neighborhood, and sums the results to produce the filtered pixel."
spatial filtering,correlation,"Correlation slides the kernel without flipping, multiplying and summing neighborhood values; it’s often used for template matching or unflipped filter responses."
spatial filtering,sharpening filters,"Sharpening filters enhance edges and fine details by emphasizing high-frequency components, using kernels such as Laplacian or unsharp masking."
spatial filtering,blurring filters,"Blurring filters like Gaussian or box filters attenuate high frequencies to smooth textures and reduce detail, creating a soft, defocused effect."
spatial filtering,combining filtering,"Combining filters, by sequential application or weighted summation, lets you craft hybrid effects like edge-preserving smoothing or detail-enhanced blurs."
spatial filtering - neighborhood,usually a rectangle around central pixel,"Rectangular windows (e.g., 5×5) are common because they align with image grids and simplify convolution implementation in hardware and software."
spatial filtering - neighborhood,can be a circle around central pixel,"Circular or elliptical neighborhoods include all pixels within a radius, offering more isotropic filtering by treating all directions equally."
spatial filtering - neighborhood,varying size filters,Changing the window size adjusts the scale of filtering: larger windows yield stronger smoothing or blurring but also risk erasing small features.
spatial filtering - neighborhood,varying shape filters,Custom shapes like crosses or donuts target specific structures or reduce computation by excluding certain neighbors from the operation.
spatial filtering - neighborhood operations,"min, minimum","The minimum filter replaces each pixel with the smallest value in its neighborhood, effectively removing bright impulses (salt noise)."
spatial filtering - neighborhood operations,"max, maximum","The maximum filter picks the largest neighborhood value for each pixel, suppressing dark impulses (pepper noise) and brightening surfaces."
spatial filtering - neighborhood operations,median,"The median filter sorts neighborhood values and selects the middle one, delivering robust noise removal while preserving edge sharpness."
spatial filtering - neighborhood operations,average,"The average (mean) filter computes the arithmetic mean of neighborhood intensities, providing simple noise reduction at the expense of some edge blurring."
spatial filtering - neighborhood operations,"linear, is reversible","Linear filters obey superposition and can be inverted if their frequency response never reaches zero, allowing theoretical recovery of the original signal."
spatial filtering - linear operations,general formula,"The spatial filtering formula is g(x,y) = Σₛ₌₋ₐᵃ Σₜ₌₋ᵦᵇ w(s,t) · f(x+s, y+t) where w(s,t) is the kernel and a, b define the half-window sizes."
spatial filtering - smoothing filters,average of pixels in neighborhood,"The mean filter replaces each pixel with the arithmetic average of its neighbors, smoothing rapid intensity variations to produce a softer image."
spatial filtering - smoothing filters,useful for removing noise,"Averaging attenuates high-frequency noise by blending each pixel with its surroundings, trading off some detail for a cleaner appearance."
spatial filtering - smoothing filters,formula,"For an M×N window, g(x,y) = (1/MN) ∑ᵢ₌₋a…ₐ ∑ⱼ₌₋b…ᵦ f(x+i, y+j), where a=(M−1)/2 and b=(N−1)/2 define the neighborhood half-sizes."
spatial filtering - weighted smoothing filters,example formula,"A Gaussian filter uses weights w(i,j) = (1/(2πσ²)) exp[−(i²+j²)/(2σ²)], so g(x,y)=∑₍i,j₎ w(i,j)·f(x+i,y+j), giving more influence to pixels near the center."
spatial filtering - weighted smoothing filters,weighted averaging,"Weighted averaging applies a nonuniform kernel—often Gaussian—so that central pixels contribute more strongly than distant ones, preserving structure while reducing noise."
spatial filtering - smoothing filters,smoothing followed by thresholding,"Applying smoothing before thresholding reduces spurious noise-induced transitions, yielding cleaner binary segmentation by stabilizing pixel values around the chosen cutoff."
spatial filtering - smoothing filters,sometimes median filter works better than averaging filter,"The median filter, by selecting the neighborhood’s middle value, resists extreme outliers and better preserves edges when impulse noise is present, outperforming mean smoothing for salt-and-pepper artifacts."
spatial filtering - smoothing filters,salt and pepper noise,"Salt-and-pepper noise randomly sets pixels to extreme black or white values; its sparse, high-amplitude impulses break down under mean smoothing but are effectively removed by median filtering."
spatial filtering - smoothing filters,"impulse noise, median filter works well","Because impulse (salt-and-pepper) noise flips a limited number of pixel values to extremes, the median operation ignores those outliers and restores the local structure."
spatial filtering - smoothing filters,but median filter is not linear,"Unlike convolution-based mean filters, the median operator is nonlinear—it lacks the superposition property—so it cannot be expressed as a simple linear kernel."
spatial filtering - smoothing filters,median filter preserves edges better than averaging filter,"Median filtering maintains sharp transitions since it chooses existing neighborhood values rather than averaging across an edge, which would blur boundaries."
spatial filtering - smoothing filters,what happens at the borders,"Near image edges, neighborhoods extend outside the valid pixel grid, requiring special handling to avoid undefined samples or artifacts."
spatial filtering - smoothing filters,preprocess before filtering operations by padding,"Padding pretends the image extends beyond its borders—by adding extra rows/columns—so that every pixel, including edge ones, has a complete neighborhood for filtering."
spatial filtering - preprocess for border anomalies,omit problematic pixels,"One approach skips any filter operations that would require out‐of‐bounds pixels, effectively shrinking the valid output region but avoiding padding."
spatial filtering - preprocess for border anomalies,pad around the borders,Zero‐padding adds a border of zeros so neighborhoods are always defined; it can darken edges but is easy to implement.
spatial filtering - preprocess for border anomalies,replicate border pixels,"Replication padding fills the border with the nearest edge pixel values, maintaining local intensity levels and reducing edge artifacts better than zero‐padding."
spatial filtering - preprocess for border anomalies,allow wrap around,"Circular padding treats the image as if it tiles the plane, wrapping neighborhoods from the opposite side, which can reduce edge bias in periodic or texture images."
spatial filtering - correlation,correlation kernel,"In correlation, the kernel slides over the image without flipping, producing g(x,y)=∑₍i,j₎ h(i,j)·f(x+i,y+j); it measures similarity between h and the local patch of f."
spatial filtering - convolution,same as correlation except with flipped kernel,"Convolution flips the filter both horizontally and vertically before sliding—g(x,y)=∑₍i,j₎ h(−i,−j)·f(x+i,y+j)—which ensures mathematical properties like commutativity and links to Fourier domain filtering."
spatial filtering - smoothing filters,correlation and convolution same if symetric kernel,"If h(i,j)=h(−i,−j), flipping doesn’t change the kernel, so correlation and convolution yield identical results for symmetric filters such as Gaussian or box kernels."
spatial filtering - sharpening filters,attempt to highlight detail,"Sharpening filters boost high-frequency components associated with edges and textures, making fine details more visible."
spatial filtering - sharpening filters,remove blurring,"By accentuating intensity transitions, sharpening filters counteract the smoothing effect of blur, restoring crispness to the image."
spatial filtering - sharpening filters,highlight edges,"Edge highlighting works by emphasizing gradients, so boundaries between regions appear more pronounced."
spatial filtering - sharpening filters,spatial differentiation,"Spatial differentiation approximates image derivatives via difference operators, detecting where intensities change rapidly."
spatial filtering - sharpening filters,"first derivative, f(x + 1) - f(x)",The simplest gradient operator computes the difference between adjacent pixels to reveal local intensity changes along one axis.
spatial filtering - sharpening filters,first derivative gives thicker edges,"A single difference yields nonzero values on both sides of an edge, producing a two-pixel-wide band instead of a single-pixel line."
spatial filtering - sharpening filters,"second derivative, f(x + 1) + f(x - 1) - 2 * f(x)","The discrete second derivative accentuates zero crossings at edges, delivering a sharper, more localized response than the first derivative."
spatial filtering - sharpening filters,gradient direction,"The edge orientation is given by arctan(∂f/∂y ÷ ∂f/∂x), indicating the angle at which intensity changes most strongly."
spatial filtering - sharpening filters,edge strength,"Edge strength is measured by the gradient magnitude √( (∂f/∂x)² + (∂f/∂y)² ), quantifying how pronounced an intensity change is at each pixel."
spatial filtering - sharpening filters,behavior of first and second derivatives around edges,"The first derivative peaks at the edge location; the second derivative crosses zero there, providing complementary cues for detection and precise localization."
spatial filtering - sharpening filters,Laplacian filter,"The Laplacian is an isotropic second-derivative operator that highlights regions of rapid intensity curvature, such as edges and fine details."
spatial filtering - Laplacian filter,formula,"In 2D discrete form, ∇²f = f(x+1,y) + f(x–1,y) + f(x,y+1) + f(x,y–1) – 4·f(x,y), summing neighbors minus four times the center."
spatial filtering - Laplacian filter,highlights edges and other discontinuities,"Because it responds strongly to intensity curvature, the Laplacian pinpoints edges, corners, and isolated spikes in the intensity surface."
spatial filtering - Laplacian filter,subtract Laplacian result from original,"Edge enhancement is done by f_sharp = f_original – ∇²f, which adds back the high-frequency detail isolated by the Laplacian."
spatial filtering - Laplacian filter,"g(x, y) = f(x, y) - Laplacian(x, y)","This formula implements the unsharp effect by combining the original image with the negated second derivative, reinforcing edges."
spatial filtering - Laplacian filter,"simplified filter, [[0, -1, 0], [-1, 5, -1], [0, -1, 0]]",This 3×3 kernel merges the subtraction and addition steps into one mask: center weight 5 minus each direct neighbor.
spatial filtering - Laplacian filter,"variant filter, [[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]]","A more aggressive sharpening kernel uses eight neighbors with –1 weight and a central weight of 9, yielding stronger edge emphasis."
spatial filtering - unsharp masking,used by the printing industry,"Unsharp masking originated in analog printmaking, where a blurred positive image was subtracted from the original to produce a mask of fine details for sharpening."
spatial filtering - unsharp masking,"mask, subtract a smooth image from an original","Create a detail mask M = f – f_smooth to isolate high-frequency content, separating edges and textures from low-frequency background."
spatial filtering - unsharp masking,add the mask to the original,The sharpened result f_sharp = f_original + k·M boosts detail by reintegrating and scaling the isolated high-frequency components.
spatial filtering - unsharp masking,highboost filter,"When k > 1, the mask is amplified before addition, producing a highboost filter that more aggressively emphasizes edges and textures."
spatial filtering - first derivative filtering,difficult in practice,"Single-difference operators are highly sensitive to noise, producing jagged or broken edges unless preceded by smoothing, making them less practical alone."
spatial filtering - sobel operators,"[[-1, -2, -1], [0, 0, 0], [1, 2, 1]] [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]","Sobel kernels combine differentiation and smoothing: one axis is differentiated while the other is averaged, producing robust gradient estimates."
spatial filtering - sobel operators,correlation and convolution are the same,"Because Sobel kernels are symmetric when flipped, performing correlation or convolution yields identical gradient outputs."
spatial filtering - combining filtering,construct a sequence of operations,"Complex effects arise by chaining filters—e.g., smooth → differentiate → threshold—or blending outputs, allowing nuanced control over enhancement and edge detection."
frequency filtering,image processing,"Frequency filtering manipulates an image’s spectral components—rather than pixels directly—to achieve effects like smoothing, sharpening, or noise removal."
frequency filtering,"DFT, discrete fourier transform","The DFT converts a spatial image f(x,y) into its frequency representation F(u,v), expressing it as a sum of complex exponentials."
frequency filtering,low pass filtering for image smoothing,"Low-pass filters attenuate high-frequency components (noise, fine details) in F(u,v), yielding a smoother image when you apply the inverse transform."
frequency filtering,high pass filtering for image sharpening,"High-pass filters preserve or amplify high frequencies associated with edges and textures, sharpening the image upon reconstruction."
frequency filtering,selective filtering for removing periodic interference,"Notch or band-reject filters can zero out specific frequency bands corresponding to periodic noise, effectively removing regular interference patterns."
frequency filtering,"IDFT, inverse discrete fourier transform","The IDFT reconstructs the spatial image from its frequency spectrum by summing complex exponentials weighted by F(u,v)F(u,v)."
frequency filtering - DFT,formula,"F(u,v)=∑x=0M−1∑y=0N−1f(x,y) e−j2π(ux/M+vy/N)F(u,v)=\sum_{x=0}^{M-1}\sum_{y=0}^{N-1}f(x,y)\,e^{-j2\pi\bigl(ux/M + vy/N\bigr)}"
frequency filtering - IDFT,formula,"f(x,y)=1MN∑u=0M−1∑v=0N−1F(u,v) ej2π(ux/M+vy/N)f(x,y)=\frac{1}{MN}\sum_{u=0}^{M-1}\sum_{v=0}^{N-1}F(u,v)\,e^{j2\pi\bigl(ux/M + vy/N\bigr)}"
frequency filtering,frequency rectangle,"The frequency rectangle is an M×N grid where each coordinate (u,v) represents a discrete spatial frequency component of the image."
frequency filtering,F is a matrix of complex numbers,"Each element F(u,v) encodes both amplitude and phase of a sinusoidal basis function that, when summed, reconstructs the image."
frequency filtering,"F(0, 0), DC component","The DC term F(0,0) captures the average intensity of the image, since it corresponds to the zero-frequency component (no oscillation)."
frequency filtering,"F(0, 0) = M * N * average of f(x, y)","By definition of the DFT, the DC coefficient equals the sum of all pixel values; dividing by MN yields the mean grey level."
frequency filtering,periodic nature,The DFT treats the image as if it repeats periodically; sharp edges at the borders produce wraparound artifacts unless mitigated by padding or windowing.
frequency filtering,spatial domain convolution is frequency domain multiplication,"Convolution in space with kernel hh corresponds to pointwise multiplication in frequency: F{f∗h}=F(u,v)⋅H(u,v)\mathcal{F}\{f * h\} = F(u,v)\cdot H(u,v)."
frequency filtering,filter transfer function,"The transfer function H(u,v) defines how each frequency component is scaled—ideal or gradual pass/stop characteristics determined by filter design."
frequency filtering,"low pass filter, same size as frequency rectangle","A low-pass filter mask H(u,v) is an M×N matrix with ones in low-frequency zones and zeros (or small values) elsewhere, matching the DFT grid."
frequency filtering,spatial domain padding to help rectify periodic nature,"Zero-padding or mirror-padding before DFT reduces border discontinuities, lessening wraparound artifacts and improving filter performance."
frequency filtering,"padding with 3 x rectangle on right, bottom, and diagonal",Extending an M×N image to 2M×2N (or larger) provides room for filter skirts and minimizes aliasing when applying large frequency-domain kernels.
frequency filtering,calculating distances within frequency rectangle,"Radial filters use distance D(u,v)=(u−M/2)2+(v−N/2)2D(u,v)=\sqrt{(u - M/2)^2 + (v - N/2)^2} from the spectrum center to define cutoffs or attenuation profiles."
frequency filtering,"ILPF, ideal lowpass filter","The ideal low-pass filter (ILPF) sets H(u,v)=1H(u,v)=1 for D(u,v)≤D0D(u,v)\le D_0 and 00 otherwise, creating a sharp circular cutoff in the frequency domain."
frequency filtering,Butterworth lowpass filter,"The Butterworth filter offers a smoother roll-off: H(u,v)=11+(D(u,v)D0)2nH(u,v)=\frac{1}{1+\left(\tfrac{D(u,v)}{D_0}\right)^{2n}}, where nn controls the slope of the transition band."
frequency filtering,Gaussian lowpass filter,"The Gaussian filter uses H(u,v)=exp⁡(−D(u,v)2/(2D02))H(u,v)=\exp\bigl(-D(u,v)^2/(2D_0^2)\bigr), providing a bell-shaped attenuation with no ringing in the spatial domain."
frequency filtering - Ideal lowpass,formula,"H(u,v)={1D(u,v)≤D00D(u,v)>D0H(u,v)=\begin{cases}1 & D(u,v)\le D_0\\0 & D(u,v)>D_0\end{cases}"
frequency filtering - Butterworth lowpass,formula,"H(u,v)=11+(D(u,v)/D0)2nH(u,v)=\dfrac{1}{1+\bigl(D(u,v)/D_0\bigr)^{2n}}"
frequency filtering - Gaussian lowpass,formula,"H(u,v)=exp⁡ ⁣(−D(u,v)2/(2D02))H(u,v)=\exp\!\bigl(-D(u,v)^2/(2D_0^2)\bigr)"
frequency filtering,highpass filters,"High-pass filters invert low-pass designs, e.g., Hhp(u,v)=1−Hlp(u,v)H_{hp}(u,v)=1 - H_{lp}(u,v), allowing high frequencies to pass while suppressing low frequencies."
frequency filtering,high frequency emphasis filtering,"Emphasis filters combine the original and high-pass result: g=f+α F−1{Hhp⋅F}g = f + \alpha\,\mathcal{F}^{-1}\{H_{hp}\cdot F\}, boosting edges without darkening the overall image."
frequency filtering,sometimes used as features for training,"Spectral magnitudes, filter responses, or radial profile statistics often serve as powerful features in machine learning applications like texture or material classification."