{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 1: The Work**\n",
        "\n",
        "The goal of this 12-step program is to show you an enhanced library for string pattern matching, using the Python programming language doing some useful work.\n",
        "\n",
        "First, let's review regular expressions which are already built into the Python programming langauge. The module is named \"re\", also refered as RE.\n",
        "\n",
        "Say we are using regular expressions to analyze a text that contains simple sentences of the form:\n",
        "\n",
        "* WHO went to WHERE looking for WHAT.\n",
        "\n",
        "For example:\n",
        "\n",
        "* I went to Louisiana, Texas and back looking for people and places.\n",
        "\n",
        "Let's write a Python program using regular expressions that extracts all of these items, WHO, WHERE, and WHAT. This program will store this information in three variables and if we are successful, the result will be the following:\n",
        "\n",
        "* who = 'I'\n",
        "* where_to = ['Louisiana', 'Texas', 'back']\n",
        "* what_for = ['people', 'places']"
      ],
      "metadata": {
        "id": "PQEhYX5ufIJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re # import the built-in regular expression module in Python\n",
        "from pprint import PrettyPrinter # import the pretty-printer object\n",
        "pp = PrettyPrinter(indent=2, width=160)\n",
        "sentences = [ # Samples of text similar to those we want to analyze:\n",
        "  \"I went to Louisiana, Texas and back looking for people and places.\"\n",
        ", \"He went to Albertsons, Aldi, and Kroger looking for pineapples, and bananas.\"\n",
        ", \"You went to school and work looking for fun, frolic and fantasy.\"\n",
        "]\n",
        "for sentence in sentences:\n",
        "    print(sentence)"
      ],
      "metadata": {
        "id": "4EVHXLcVj4pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 2: It's off to work we go.**\n",
        "\n",
        "Let's try using the *re.search* function.\n",
        "\n",
        "After a successful regular expression match, the *re.search* returns an *re.Match* object. To nicely display any Python object, the pretty-print function, *pprint*, is used. To gain access to any captured groups being returned, the *re.Match.groups* (or *re.Match.groupdict*) is used. The *groups* function returns a list of positionally captured groups and the *groupdict* function returns a dictionary of named captured groups.\n",
        "\n",
        "This is going to be amazing! You mean all I have to do is create just one regular expression pattern to verify the validity of the text and simulataneously extract all the separate elements into structured data in *one fell swoop*?"
      ],
      "metadata": {
        "id": "Mxe6d4ianpRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in sentences:\n",
        "    if results := re.search(\n",
        "          r\"^(I|He|You)\"                          # the caret denotes to match beginning of string\n",
        "                                                  # (___), parenthesis, denotes to group and to capture\n",
        "                                                  # _|_|_, the vertical-bar, denotes to match alternatives\n",
        "          r\" went to \"                            # nothing special denotes to match this text literally\n",
        "          r\"([A-Za-z][a-z]*)\"                     # [A-Za-z][a-z]* denotes to match a word, possibly capitalized\n",
        "          r\"(?:(?:,|,? and) ([A-Za-z][a-z]*))*\"   # ___? denotes to match optionally, zero or one instances\n",
        "                                                  # (___)* denotes matching a repetition of zero or more patterns\n",
        "                                                  # (?:___) denotes to group but not to capture\n",
        "                                                  # (?:(?:___) (___))*\n",
        "                                                  #   comma or conjunction, or both\n",
        "                                                  #   followed by a space\n",
        "                                                  #   followed by a word possibly capitalized\n",
        "          r\" looking for \"                        # match literal text\n",
        "          r\"([A-Za-z][a-z]*)\"                     # group and capture the 1st thing\n",
        "          r\"(?:(?:,|,? and) ([A-Za-z][a-z]*))*\"   # also capture all remaining things\n",
        "                                                  # but ignore commas, spaces, and the word \"and\"\n",
        "          r\"\\.$\"                                  # the period character must be escaped with a backslash\n",
        "                                                  # the dollar-sign denotes to match end of the string\n",
        "        , sentence):\n",
        "          pp.pprint([\"Matched:\", results.groups(), sentence])\n",
        "    else: pp.pprint([\"Unmatched!\", sentence])"
      ],
      "metadata": {
        "id": "aBsk2qvTkR9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 3: What happened? I can't do my work.**\n",
        "\n",
        "Where is Texas, Aldi, and frolic?\\\n",
        "Where are the two lists for the places and things?\\\n",
        "I think I might have choosen unwisely.\\\n",
        "\\\n",
        "Maybe there is a bug? Can it be that the construct (?:___) specifying a non-capturing group is in some way interferring with properly capturing its nested pattern? So let's modify these to simply be capturing groups instead."
      ],
      "metadata": {
        "id": "svxEw0WCpRZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in sentences:\n",
        "    if results := re.search(\n",
        "          r\"^(I|He|You)\"\n",
        "          r\" went to\"\n",
        "          r\" ([A-Za-z][a-z]*)\"\n",
        "          r\"((?:,|,? and) ([A-Za-z][a-z]*))*\" # (?:(?:___) (___))* becomes ((?:___) (___))*\n",
        "          r\" looking for\"\n",
        "          r\" ([A-Za-z][a-z]*)\"\n",
        "          r\"((?:,|,? and) ([A-Za-z][a-z]*))*\" # (?:(?:___) (___))* becomes ((?:___) (___))*\n",
        "          r\"\\.$\"\n",
        "        , sentence):\n",
        "          pp.pprint([\"Matched:\", results.groups(), sentence])\n",
        "    else: pp.pprint([\"Unmatched!\", sentence])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qcnqqlBAb1JA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 4: What happened? I still can't do my work.**\n",
        "\n",
        "Things seem worse than before.\\\n",
        "I think I might have choosen unwisely.\\\n",
        "\\\n",
        "Can it be that capturing elements of a reptition just isn't possible?\\\n",
        "Can it be that the *re.search* function will just not return a list of elements?\\\n",
        "Unfortunately, the RE module is working as designed and hence this limitation will likely never to be lifted. It will only ever just return the last element of the repitition, and will always refuse to capture the remaining parts.\\\n",
        "\\\n",
        "Unfortunately, the developers of the RE module might just have built this bug into the product as a feature. So, let's try one more time. Let's at least attempt to capture the entire text of these lists and not capture their nested elements."
      ],
      "metadata": {
        "id": "E_19QoZ9_2d4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in sentences:\n",
        "    if results := re.search(\n",
        "          r\"^(I|He|You)\"\n",
        "          r\" went to\"\n",
        "          r\" ([A-Za-z][a-z]*)\"\n",
        "          r\"((?:(?:,|,? and) (?:[A-Za-z][a-z]*))*)\" # ((?:___) (___))* becomes ((?:(?:___) (___))*)\n",
        "          r\" looking for\"\n",
        "          r\" ([A-Za-z][a-z]*)\"\n",
        "          r\"((?:(?:,|,? and) (?:[A-Za-z][a-z]*))*)\" # ((?:___) (___))* becomes ((?:(?:___) (___))*)\n",
        "          r\"\\.$\"\n",
        "        , sentence):\n",
        "          pp.pprint([\"Matched:\", results.groups(), sentence])\n",
        "    else: pp.pprint([\"Unmatched!\", sentence])"
      ],
      "metadata": {
        "id": "DceWdhAZi8PW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 5: What happens now? There is more work to be done.**\n",
        "\n",
        "So, it appears this caliber of results is the best we can accomplish using the RE module, and that our initial desire to develop one regular expression pattern to extract structured data from text will not be fulfilled. For this task, it appears more coding will be necessary. Oh but I desperately wanted to avoid procedural coding all together. I wanted the pattern to look similar to the subject. I want the solution to resemble the problem.\n",
        "\n",
        "Since we are limited to having just a single capture group to return a repitition in its entirety, and since individual elements can not be captured, let's at least merge the patterns for the first and remaining parts into one pattern for a proper comma-seperated string for later processing."
      ],
      "metadata": {
        "id": "SccsrGXPGq-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in sentences:\n",
        "    if results := re.search(\n",
        "          r\"^(I|He|You)\"\n",
        "          r\" went to\"\n",
        "          r\" (\"\n",
        "              r\"(?:[A-Za-z][a-z]*)\"\n",
        "              r\"(?:(?:,|,? and) (?:[A-Za-z][a-z]*))*\"\n",
        "          r\")\" # ((___)(?:(?:___) (___))*) becomes ((?:___)(?:(?:___) (___))*)\n",
        "          r\" looking for\"\n",
        "          r\" (\"\n",
        "              r\"(?:[A-Za-z][a-z]*)\"\n",
        "              r\"(?:(?:,|,? and) (?:[A-Za-z][a-z]*))*\"\n",
        "          r\")\" # ((___)(?:(?:___) (___))*) becomes ((?:___)(?:(?:___) (___))*)\n",
        "          r\"\\.$\"\n",
        "        , sentence):\n",
        "          pp.pprint([\"Matched:\", results.groups(), sentence])\n",
        "    else: pp.pprint([\"Unmatched!\", sentence])"
      ],
      "metadata": {
        "id": "KxNPTtfyn1kZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 6: So now what happens? So much work. So little time.**\n",
        "\n",
        "I must write more Python code! Ooh, somebody stop me."
      ],
      "metadata": {
        "id": "r1i3s9BaMCTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in sentences:\n",
        "    if results := re.search(\n",
        "          # (?P<name>___) denotes to match, group and capture by name\n",
        "          r\"^(?P<who>I|He|You)\"\n",
        "          r\" went to\"\n",
        "          r\" (?P<where>\"\n",
        "            r\"(?:[A-Za-z][a-z]*)\"\n",
        "            r\"(?:(?:,|,? and)? (?:[A-Za-z][a-z]*))*\"\n",
        "          r\")\" # (?P<where>___) denotes to capture group named where\n",
        "          r\" looking for\"\n",
        "          r\" (?P<what>\"\n",
        "            r\"(?:[A-Za-z][a-z]*)\"\n",
        "            r\"(?:(?:,|,? and)? (?:[A-Za-z][a-z]*))*\"\n",
        "          r\")\" # 'who', 'where', and 'what' are keys of groupdict()\n",
        "          r\"\\.$\"\n",
        "        , sentence):\n",
        "          who = results.groupdict()['who']\n",
        "          where_to = []\n",
        "          for word_results in re.finditer(\n",
        "              r\"(?:(?:^|,? |,? and )(?!and)(?P<word>[A-Za-z][a-z]*))\",\n",
        "              results.groupdict()['where']\n",
        "          ):  where_to.append(word_results.groupdict()['word'])\n",
        "          what_for = []\n",
        "          for word_results in re.finditer(\n",
        "              r\"(?:(?:^|,? |,? and )(?!and)(?P<word>[A-Za-z][a-z]*))\",\n",
        "              results.groupdict()['what']\n",
        "          ):  what_for.append(word_results.groupdict()['word'])\n",
        "          pp.pprint([\"Matched:\", who, where_to, what_for, sentence])\n",
        "    else: pp.pprint([\"Unmatched!\", sentence])"
      ],
      "metadata": {
        "id": "vAjOHmHFqkqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 7: So what happened there? A beautiful mess.**\n",
        "\n",
        "But it works. It validates the input text and produces three variables, one containing who, and two containing the list of where to and what for.\n",
        "\n",
        "But is there another way?\\\n",
        "Let's try using the SNOBOL4python library instead.\\\n",
        "The following code will mount and import the SNOBOL4python package."
      ],
      "metadata": {
        "id": "tQte7gc0QCu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SNOBOL4python==0.4.5\n",
        "import sys\n",
        "from pprint import pprint, pformat\n",
        "## Thirty one (31) flavors of patterns to choose from ...\n",
        "from SNOBOL4python import ε, σ, π, λ, Λ, ζ, θ, Θ, φ, Φ, α, ω\n",
        "from SNOBOL4python import ABORT, ANY, ARB, ARBNO, BAL, BREAK, BREAKX, FAIL\n",
        "from SNOBOL4python import FENCE, LEN, MARB, MARBNO, NOTANY, POS, REM, RPOS\n",
        "from SNOBOL4python import RTAB, SPAN, SUCCEED, TAB\n",
        "# Miscellaneous\n",
        "from SNOBOL4python import GLOBALS, TRACE, PATTERN, Ϩ, STRING\n",
        "from SNOBOL4python import ALPHABET, DIGITS, UCASE, LCASE, NULL\n",
        "from SNOBOL4python import nPush, nInc, nPop, Shift, Reduce, Pop\n",
        "GLOBALS(globals()) # Instantiate the global variable space"
      ],
      "metadata": {
        "id": "xXcseKB7CUY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 8: What's happening? A new way. A new hope.**\n",
        "\n",
        "To use the new PATTERN datatype provided by the SNOBOL4python Python module:\n",
        "\n",
        "*   r\"^\" becomes *POS*(0)\n",
        "*   r\"$\" becomes *RPOS*(0)\n",
        "*   r\"[a-z]\" becomes *ANY*(LCASE)\n",
        "*   r\"xyz\" becomes σ('xyz'), or alternatively\n",
        "*   r\"xyz\" becomes σ('x') + σ('y') + σ('z')\n",
        "*   r\"x|z\" becomes σ('x') | σ('z')\n",
        "*   r\"(\\_\\_\\_)*\" becomes *ARBNO*(___)\n",
        "*   re.search(pattern, subject) becomes subject in PATTERN\n",
        "\n",
        "Let's start by just getting the PATTERN to work, and not dealing with capturing any results."
      ],
      "metadata": {
        "id": "O5zs7ytMTtww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word = ANY(UCASE+LCASE) + (SPAN(LCASE) | ε())\n",
        "delimiter = σ(', and ') | σ(' and ') | σ(', ')\n",
        "for sentence in sentences:\n",
        "    if sentence in \\\n",
        "          ( POS(0)\n",
        "          + (σ('I') | σ('He') | σ('You'))\n",
        "          + σ(' went to ')\n",
        "          + word + ARBNO(delimiter + word)\n",
        "          + σ(' looking for ')\n",
        "          + word + ARBNO(delimiter + word)\n",
        "          + σ('.')\n",
        "          + RPOS(0)\n",
        "          ):\n",
        "          pp.pprint(['Matched.', sentence])\n",
        "    else: pp.pprint(['Unmatched!', sentence])"
      ],
      "metadata": {
        "id": "TLU_r-IxIsTs",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 9: It's happening! My work is getting done.**\n",
        "\n",
        "Now, let's decorate the above pattern with Python code to capture the PATTERN matching results into variables containing strings and lists.\n",
        "\n",
        "* r\"(?P\\<name>\\_\\_\\_) becomes ___ % \"name\"\n",
        "* r\"*no-can-do*\" becomes λ(\"*python_code_string*\")"
      ],
      "metadata": {
        "id": "LKBSWdjTXmBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word = (ANY(UCASE+LCASE) + (SPAN(LCASE) | ε())) % \"wrd\"\n",
        "delimiter = (σ(', and ') | σ(' and ') | σ(', '))\n",
        "for sentence in sentences:\n",
        "    if sentence in \\\n",
        "          ( POS(0)\n",
        "          + (σ('I') | σ('He') | σ('You')) % \"who\"\n",
        "          + σ(' went to ')     + word + λ(\"where_to = [wrd]\")\n",
        "          + ARBNO(delimiter    + word + λ(\"where_to.append(wrd)\"))\n",
        "          + σ(' looking for ') + word + λ(\"what_for = [wrd]\")\n",
        "          + ARBNO(delimiter    + word + λ(\"what_for.append(wrd)\"))\n",
        "          + σ('.')\n",
        "          + RPOS(0)\n",
        "          ):\n",
        "          pp.pprint(['Matched:', who, where_to, what_for, sentence])\n",
        "    else: pp.pprint(['Unmatched!', None, None, None, sentence])"
      ],
      "metadata": {
        "id": "ag46QkLiLxS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 10: It happened! My work is done.**\n",
        "\n",
        "Can it really be that easy? The solution resembles a description of the problem.\n",
        "\n",
        "Using the theta function and immediate assignment operator in conjunction with the OUTPUT variable, you can trace the progress of the pattern matching scanner."
      ],
      "metadata": {
        "id": "ctVAfPVabVvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word = Θ(\"OUTPUT\") + (ANY(UCASE+LCASE) + (SPAN(LCASE) | ε())) @ \"OUTPUT\"\n",
        "delimiter = Θ(\"OUTPUT\") + (σ(', and ') | σ(' and ') | σ(', ')) @ \"OUTPUT\"\n",
        "for sentence in sentences:\n",
        "    if sentence in \\\n",
        "          ( Θ(\"OUTPUT\") + POS(0)\n",
        "          + Θ(\"OUTPUT\") + (σ('I') | σ('He') | σ('You')) @ \"OUTPUT\"\n",
        "          + Θ(\"OUTPUT\") + σ(' went to ') @ \"OUTPUT\"\n",
        "                         + word + ARBNO(delimiter + word)\n",
        "          + Θ(\"OUTPUT\") + σ(' looking for ') @ \"OUTPUT\"\n",
        "                        + word + ARBNO(delimiter + word)\n",
        "          + Θ(\"OUTPUT\") + σ('.') @ \"OUTPUT\"\n",
        "          + Θ(\"OUTPUT\") + RPOS(0)\n",
        "          ):\n",
        "          print(f'Matched: {sentence}\\n')\n",
        "    else: print(f'Unmatched! {sentence}\\n')"
      ],
      "metadata": {
        "id": "SSWCDnbVwvUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 11: It happened! My work is ensured.**\n",
        "\n",
        "Now introducing the PATTERN phi, φ(r'___'). It will match a regular expression. And now a solution using regular expression patterns as an integral part of the new PATTERN datatype."
      ],
      "metadata": {
        "id": "Na_FLTdVRaDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word = φ(r'(?P<wrd>[A-Za-z][a-z]*)')\n",
        "delimiter = φ(r'(?:,? and|,) ')\n",
        "for sentence in sentences:\n",
        "    if sentence in \\\n",
        "          ( φ(r'^')\n",
        "          + (φ(r'(?P<who>I|He|You)'))\n",
        "          + φ(r' went to ')     + word + λ(\"where_to = [wrd]\")\n",
        "          + ARBNO(delimiter     + word + λ(\"where_to.append(wrd)\"))\n",
        "          + φ(r' looking for ') + word + λ(\"what_for = [wrd]\")\n",
        "          + ARBNO(delimiter     + word + λ(\"what_for.append(wrd)\"))\n",
        "          + φ(r'\\.$')\n",
        "          ):\n",
        "          pp.pprint(['Matched:', who, where_to, what_for, sentence])\n",
        "    else: pp.pprint(['Unmatched!', None, None, None, sentence])"
      ],
      "metadata": {
        "id": "wWh-7L0dNEfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 12: What happens next. You can do any work you want!**\n",
        "\n",
        "This SNOBOL4python module can process all four levels of the Chompsky heirarchy.\\\n",
        "This concludes this 12-step program.\\\n",
        "Now enjoy nirvana by seeing some real-world examples.\n",
        "\n",
        "Let's process those TASA Treebank trees in the file from assignment #3, but let's first process those same sentences after being POS tagged by the UCREL CLAWS."
      ],
      "metadata": {
        "id": "i-6U2Ze2fMJy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 12+1: Example 1: UCREL CLAWS POS-tagged sentences from assignment #3**"
      ],
      "metadata": {
        "id": "HTvpcaR4v5ZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLAWS_5_in_TASA = \"\"\"\\\n",
        "1_CRD :_PUN That_CJT the_AT0 power_NN1 of_PRF taxing_VVG it_PNP by_PRP the_AT0\n",
        "states_NN2 may_VM0 be_VBI exercised_VVN so_AV0 as_AV0 to_TO0 destroy_VVI\n",
        "it_PNP ,_PUN is_VBZ too_AV0 obvious_AJ0 to_TO0 be_VBI denied_VVN ._PUN\n",
        "2_CRD :_PUN None_PNI ever_AV0 penned_VVD a_AT0 manifesto_NN1 as_AV0\n",
        "stirring_AJ0 as_CJS the_AT0 one_PNI that_CJT appeared_VVD in_PRP the_AT0\n",
        "first_ORD issue_NN1 of_PRF the_AT0 liberator_NN1 ,_PUN and_CJC no_AT0\n",
        "other_AJ0 abolitionist_NN1 document_NN1 is_VBZ so_AV0 well_AV0 remembered_VVN\n",
        "._PUN\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "cgQ4k3ljW0nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "claws_info = \\\n",
        "    ( POS(0)\n",
        "    + λ(\"mem = dict()\")\n",
        "    + ARBNO(\n",
        "        ( SPAN(DIGITS) % \"num\" + σ('_CRD :_PUN')\n",
        "        + λ(\"num = int(num)\")\n",
        "        | (NOTANY(\"_\") + BREAK(\"_\")) % \"wrd\"\n",
        "        + σ('_')\n",
        "        + (ANY(UCASE) + SPAN(DIGITS+UCASE)) % \"tag\"\n",
        "        + λ(\"if wrd not in mem:      mem[wrd] = dict()\")\n",
        "        + λ(\"if tag not in mem[wrd]: mem[wrd][tag] = 0\")\n",
        "        + λ(\"mem[wrd][tag] += 1\")\n",
        "        )\n",
        "      + (σ(' \\n') | σ(' ') | σ('\\n'))\n",
        "      )\n",
        "    + RPOS(0)\n",
        "    )\n",
        "pp.pprint(claws_info)"
      ],
      "metadata": {
        "id": "2xZaWiFHXg_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mem = None\n",
        "if CLAWS_5_in_TASA in claws_info:\n",
        "    pp.pprint(mem)\n",
        "else: print(\"Boo!\")"
      ],
      "metadata": {
        "id": "0zCdLxdBswAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{ ',': {'PUN': 2}, '.': {'PUN': 2},\n",
        "  'None': {'PNI': 1}, 'That': {'CJT': 1},\n",
        "  'a': {'AT0': 1}, 'abolitionist': {'NN1': 1}, 'and': {'CJC': 1},\n",
        "  'appeared': {'VVD': 1}, 'as': {'AV0': 2, 'CJS': 1},\n",
        "  'be': {'VBI': 2}, 'by': {'PRP': 1},\n",
        "  'denied': {'VVN': 1}, 'destroy': {'VVI': 1}, 'document': {'NN1': 1},\n",
        "  'ever': {'AV0': 1}, 'exercised': {'VVN': 1},\n",
        "  'first': {'ORD': 1}, 'in': {'PRP': 1},\n",
        "  'is': {'VBZ': 2}, 'issue': {'NN1': 1}, 'it': {'PNP': 2},\n",
        "  'liberator': {'NN1': 1},\n",
        "  'manifesto': {'NN1': 1}, 'may': {'VM0': 1},\n",
        "  'no': {'AT0': 1},\n",
        "  'obvious': {'AJ0': 1}, 'of': {'PRF': 2}, 'one': {'PNI': 1}, 'other': {'AJ0': 1},\n",
        "  'penned': {'VVD': 1}, 'power': {'NN1': 1},\n",
        "  'remembered': {'VVN': 1},\n",
        "  'so': {'AV0': 2}, 'states': {'NN2': 1}, 'stirring': {'AJ0': 1},\n",
        "  'taxing': {'VVG': 1}, 'that': {'CJT': 1}, 'the': {'AT0': 5}, 'to': {'TO0': 2},\n",
        "  'too': {'AV0': 1},\n",
        "  'well': {'AV0': 1}\n",
        "}"
      ],
      "metadata": {
        "id": "saCtjZx8S9a7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This next example requires the file \"CLAWS5inTASA.dat\" on your Google Drive\n",
        "# Skip this one step if you don't have the file.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/modules', force_remount=True)\n",
        "sys.path.append('/content/modules/My Drive/')"
      ],
      "metadata": {
        "id": "fEhvU0vucDGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mem = None\n",
        "with open(\"/content/modules/My Drive/CLAWS5inTASA.dat\", \"r\") as claws_file:\n",
        "    lines = []\n",
        "    while line := claws_file.readline():\n",
        "        lines.append(line[0:-1])\n",
        "    claws_data = ''.join(lines)\n",
        "    if not claws_data in claws_info:\n",
        "        print(\"Yikes\")\n",
        "    pp.pprint(mem)"
      ],
      "metadata": {
        "id": "dBIzt2t6htG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 12+2: Example 2: Penn Treebank grammar trees from assignment #3**"
      ],
      "metadata": {
        "id": "0SAixQaTwNLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VBG_in_TASA = \"\"\"\\\n",
        "(S (SBAR (IN that) (S (NP (NP (DT the) (NN power)) (PP (IN of) (S (VP (VBG\n",
        "taxing) (NP (PRP it)) (PP (IN by) (NP (DT the) (NNS states))))))) (VP (MD\n",
        "may) (VP (VB be) (VP (VBN exercised) (ADVP (RB so) (RB as)) (S (VP (TO to)\n",
        "(VP (VB destroy) (NP (PRP it))))))))) (, ,)) (VP (VBZ is) (ADJP (RB too)\n",
        "(JJ obvious)) (S (VP (TO to) (VP (VB be) (VP (VBN denied)))))) (.  .))\n",
        "\n",
        "(S (S (NP (NN none)) (ADVP (RB ever)) (VP (VBN penned) (NP (DT a) (NN\n",
        "manifesto)) (PP (IN as) (S (VP (VBG stirring) (PP (IN as) (NP (NP (DT the)\n",
        "(NN one)) (SBAR (WHNP (WDT that)) (S (VP (VBD appeared) (PP (IN in) (NP (NP\n",
        "(DT the) (JJ first) (NN issue)) (PP (IN of) (NP (DT the) (NN\n",
        "liberator))))))))))))))) (, ,) (CC and) (S (NP (DT no) (JJ other) (NN\n",
        "abolitionist) (NN document)) (VP (VBZ is) (ADVP (RB so) (RB well)) (VP (VBN\n",
        "remembered)))) (.  .))\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ts6krpoOoM8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delim     = SPAN(\" \\n\")\n",
        "word      = NOTANY(\"( )\\n\") + BREAK(\"( )\\n\")\n",
        "group     = σ('(') + word + ARBNO(delim + (ζ('group') | word)) + σ(')')\n",
        "treebank  = POS(0) + ARBNO(ARBNO(group) + delim) + RPOS(0)\n",
        "VBG_in_TASA in treebank # % \"OUTPUT\""
      ],
      "metadata": {
        "id": "xJXHTtf0kwdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_list(v): return λ(f\"{v} = None; stack = []\")\n",
        "def push_list(v): return λ(f\"stack.append(list()); stack[-1].append({v})\")\n",
        "def push_item(v): return λ(f\"stack[-1].append({v})\")\n",
        "def pop_list():   return λ(f\"stack[-2].append(tuple(stack.pop()))\")\n",
        "def pop_final(v): return λ(f\"{v} = tuple(stack.pop())\")\n",
        "delim =           SPAN(\" \\n\")\n",
        "word =            NOTANY(\"( )\\n\") + BREAK(\"( )\\n\")\n",
        "group =           ( σ('(')\n",
        "                  + word % \"tag\"\n",
        "                  + push_list(\"tag\")\n",
        "                  + ARBNO(delim + (ζ('group') | word % \"wrd\" + push_item(\"wrd\")))\n",
        "                  + pop_list()\n",
        "                  + σ(')')\n",
        "                  )\n",
        "treebank =        ( POS(0)\n",
        "                  + init_list(\"bank\")\n",
        "                  + push_list(\"'BANK'\")\n",
        "                  + ARBNO(push_list(\"'ROOT'\") + ARBNO(group) + pop_list() + delim)\n",
        "                  + pop_final(\"bank\")\n",
        "                  + RPOS(0)\n",
        "                  )\n",
        "pp.pprint([delim, word, group, treebank])"
      ],
      "metadata": {
        "id": "vGr2lhyNk451"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bank = None\n",
        "if VBG_in_TASA in treebank:\n",
        "    pp.pprint(bank[1])\n",
        "else: print(\"Boo!\")"
      ],
      "metadata": {
        "id": "7DBGagw9oNh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This next example requires the file \"VBGinTASA.dat\" on your Google Drive.\n",
        "# Skip this one step if you don't have the file."
      ],
      "metadata": {
        "id": "6QlksO9_upCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bank = None\n",
        "with open(\"/content/modules/My Drive/VBGinTASA.dat\", \"r\") as bank_file:\n",
        "    bank_source = bank_file.read()\n",
        "    if bank_source in POS(0) + BAL() + RPOS(0):\n",
        "        if bank_source in treebank:\n",
        "            print(len(bank), \"trees processed.\")\n",
        "    else: print(\"Boo!\")"
      ],
      "metadata": {
        "id": "3UJCXHi7lTjN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}